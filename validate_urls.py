#!/usr/bin/env python3
"""
URL Validator for Processed Markdown Files

This script scans all processed markdown files to ensure URLs are properly normalized
to be absolute paths or valid external URLs.
"""

import re
import sys
from pathlib import Path
from typing import List, Tuple, Set
import argparse


class URLValidator:
    def __init__(self, base_dir: str):
        self.base_dir = Path(base_dir)
        self.issues = []

    def extract_urls_from_markdown(self, content: str, file_path: str) -> List[Tuple[str, int, str]]:
        """Extract all URLs from markdown content."""
        urls = []
        lines = content.split('\n')

        # Pattern to match markdown links [text](url)
        link_pattern = r'\[([^\]]*)\]\(([^)]+)\)'

        for line_num, line in enumerate(lines, 1):
            matches = re.finditer(link_pattern, line)
            for match in matches:
                text, url = match.groups()
                urls.append((url, line_num, text))

        return urls

    def validate_url(self, url: str) -> dict:
        """Validate a single URL and return validation results."""
        result = {
            'url': url,
            'is_valid': True,
            'issues': []
        }

        # Check for valid absolute URLs
        if url.startswith(('http://', 'https://')):
            result['type'] = 'external'
            return result

        # Check for absolute paths (relative to site root)
        if url.startswith('/'):
            result['type'] = 'absolute'
            return result

        # Check for anchor links
        if url.startswith('#'):
            result['type'] = 'anchor'
            return result

        # Special URLs that are OK to be relative
        if url.startswith(('mailto:', 'tel:', 'javascript:')):
            result['type'] = 'special'
            return result

        # Skip API reference links (these are generated by Hugo from TypeDoc)
        if '../packages/' in url or url in ['Protocol']:
            result['type'] = 'api-reference'
            return result

        # Accept relative paths that are within md-processed directory structure
        if url.startswith('../') or url.startswith('./') or (not url.startswith('/') and not '://' in url):
            result['type'] = 'relative'
            # Only flag as invalid if it seems to go way outside the structure
            if url.count('../') > 10:  # Very generous limit
                result['is_valid'] = False
                result['issues'].append(f"URL may go outside md-processed directory: '{url}'")
            return result

        # Should not reach here, but handle unexpected cases
        result['is_valid'] = False
        result['issues'].append(f"Unexpected URL format: '{url}'")
        result['type'] = 'unknown'

        return result

    def scan_file(self, file_path: Path) -> None:
        """Scan a single markdown file for URL issues."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            urls = self.extract_urls_from_markdown(content, str(file_path))

            for url, line_num, link_text in urls:
                validation = self.validate_url(url)

                if not validation['is_valid']:
                    self.issues.append({
                        'file': str(file_path.relative_to(self.base_dir)),
                        'line': line_num,
                        'url': url,
                        'text': link_text,
                        'issues': validation['issues']
                    })

        except Exception as e:
            print(f"Error reading {file_path}: {e}", file=sys.stderr)

    def scan_directory(self) -> None:
        """Scan all markdown files in the directory tree."""
        md_files = list(self.base_dir.rglob('*.txt'))  # Hugo outputs .txt for MD format
        print(f"Scanning {len(md_files)} markdown files...")

        for file_path in md_files:
            self.scan_file(file_path)

    def report(self) -> bool:
        """Generate and print the validation report."""
        if not self.issues:
            print("✅ All URLs are properly normalized!")
            return True

        print(f"❌ Found {len(self.issues)} URL issues:")
        print()

        for issue in self.issues:
            print(f"File: {issue['file']}:{issue['line']}")
            print(f"  Link: [{issue['text']}]({issue['url']})")
            for problem in issue['issues']:
                print(f"  Issue: {problem}")
            print()

        return False

    def get_url_statistics(self) -> dict:
        """Get statistics about URL types found."""
        stats = {
            'external': 0,
            'absolute': 0,
            'anchor': 0,
            'relative': 0,
            'special': 0,
            'api-reference': 0,
            'total': 0
        }

        md_files = list(self.base_dir.rglob('*.txt'))
        all_urls = []

        for file_path in md_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                urls = self.extract_urls_from_markdown(content, str(file_path))
                all_urls.extend(urls)
            except:
                continue

        for url, _, _ in all_urls:
            validation = self.validate_url(url)
            stats[validation['type']] += 1
            stats['total'] += 1

        return stats


def main():
    parser = argparse.ArgumentParser(description='Validate URLs in processed markdown files')
    parser.add_argument('directory', help='Directory containing processed markdown files')
    parser.add_argument('--stats', action='store_true', help='Show URL statistics')
    args = parser.parse_args()

    validator = URLValidator(args.directory)

    if args.stats:
        stats = validator.get_url_statistics()
        print("URL Statistics:")
        print(f"  Total URLs: {stats['total']}")
        print(f"  External (http/https): {stats['external']}")
        print(f"  Absolute paths (/...): {stats['absolute']}")
        print(f"  Anchor links (#...): {stats['anchor']}")
        print(f"  API Reference links: {stats['api-reference']}")
        print(f"  Relative paths (need fixing): {stats['relative']}")
        print(f"  Special (mailto/tel/etc): {stats['special']}")
        print()

    validator.scan_directory()
    success = validator.report()

    return 0 if success else 1


if __name__ == '__main__':
    sys.exit(main())