diff --git a/.gitignore b/.gitignore
index 642d7562..c3aa91c8 100644
--- a/.gitignore
+++ b/.gitignore
@@ -30,7 +30,6 @@ link_checker_output.json
 .idea
 
 # Do not save temporary uv settings
-pyproject.toml
 .venv/
 main.py
 .python-version
diff --git a/CLOUDFLARE_BUILD.md b/CLOUDFLARE_BUILD.md
new file mode 100644
index 00000000..e6b7d110
--- /dev/null
+++ b/CLOUDFLARE_BUILD.md
@@ -0,0 +1,60 @@
+# Cloudflare Pages Configuration
+
+## Build Settings
+
+Configure your Cloudflare Pages project with these settings:
+
+### Framework preset
+**None** (Custom/Static site)
+
+### Build command
+```bash
+chmod +x build.sh && ./build.sh
+```
+
+### Build output directory
+```bash
+dist
+```
+
+### Root directory
+```bash
+/
+```
+
+### Environment variables
+Set these in your Cloudflare Pages dashboard:
+
+- `PYTHON_VERSION`: `3.9` (or higher)
+- `NODE_VERSION`: `18` (or higher)
+
+## How it works
+
+1. The `build.sh` script installs Python dependencies using pip3
+2. Runs `make dist` which builds all documentation variants
+3. The Python processor (`process_shortcodes.py`) converts Hugo shortcodes to markdown
+4. Output is generated in the `dist/` directory for Cloudflare Pages
+
+## Local Testing
+
+To test the build process locally (without UV):
+
+```bash
+# Install dependencies
+pip3 install -r requirements.txt
+
+# Run build
+chmod +x build.sh
+./build.sh
+```
+
+## Troubleshooting
+
+If the build fails:
+
+1. Check that Python 3.8+ is available
+2. Verify that `toml` package can be installed
+3. Check Hugo version compatibility (supports 0.145.0+)
+4. Review build logs for specific Python errors
+
+The build script automatically falls back from `uv run` to `python3` if UV is not available.
\ No newline at end of file
diff --git a/Makefile b/Makefile
index bbd52e14..66cb546d 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@ PREFIX := $(if $(VERSION),docs/$(VERSION),docs)
 PORT := 9000
 BUILD := $(shell date +%s)
 
-.PHONY: all dist variant dev update-examples sync-examples
+.PHONY: all dist variant dev update-examples sync-examples llm-docs
 
 all: usage
 
@@ -26,11 +26,28 @@ dist: base
 	# make variant VARIANT=serverless
 	make variant VARIANT=byoc
 	make variant VARIANT=selfmanaged
+	make llm-docs
 
 variant:
 	@if [ -z ${VARIANT} ]; then echo "VARIANT is not set"; exit 1; fi
 	@VERSION=${VERSION} ./scripts/run_hugo.sh --config hugo.toml,hugo.site.toml,hugo.ver.toml,config.${VARIANT}.toml --destination dist/${VARIANT}
 	@VERSION=${VERSION} VARIANT=${VARIANT} PREFIX=${PREFIX} BUILD=${BUILD} ./scripts/gen_404.sh
+	@echo "Processing shortcodes in markdown files..."
+	@if [ -d "dist/docs/v2/${VARIANT}/tmp-md" ]; then \
+		if command -v uv >/dev/null 2>&1; then \
+		uv run process_shortcodes.py \
+			--variant=${VARIANT} \
+			--input-dir=dist/docs/v2/${VARIANT}/tmp-md \
+			--output-dir=dist/docs/v2/${VARIANT}/md \
+			--base-path=.; \
+		else \
+		python3 process_shortcodes.py \
+			--variant=${VARIANT} \
+			--input-dir=dist/docs/v2/${VARIANT}/tmp-md \
+			--output-dir=dist/docs/v2/${VARIANT}/md \
+			--base-path=.; \
+		fi \
+	fi
 
 dev:
 	@if ! ./scripts/pre-flight.sh; then exit 1; fi
@@ -53,3 +70,42 @@ check-jupyter:
 
 check-images:
 	./scripts/check_images.sh
+
+validate-urls:
+	@echo "Validating URLs across all variants..."
+	for variant in flyte byoc selfmanaged; do \
+		echo "Checking $$variant..."; \
+		if [ -d "dist/docs/v2/$$variant/md" ]; then \
+			if command -v uv >/dev/null 2>&1; then \
+				uv run python3 validate_urls.py dist/docs/v2/$$variant/md; \
+			else \
+				python3 validate_urls.py dist/docs/v2/$$variant/md; \
+			fi; \
+		else \
+			echo "No processed markdown found for $$variant"; \
+		fi \
+	done
+
+url-stats:
+	@echo "URL statistics across all variants:"
+	for variant in flyte byoc selfmanaged; do \
+		echo "=== $$variant ==="; \
+		if [ -d "dist/docs/v2/$$variant/md" ]; then \
+			if command -v uv >/dev/null 2>&1; then \
+				uv run python3 validate_urls.py dist/docs/v2/$$variant/md --stats; \
+			else \
+				python3 validate_urls.py dist/docs/v2/$$variant/md --stats; \
+			fi; \
+		else \
+			echo "No processed markdown found for $$variant"; \
+		fi \
+	done
+
+llm-docs:
+	@echo "Building LLM-optimized documentation..."
+	@if command -v uv >/dev/null 2>&1; then \
+		uv run build_llm_docs.py --no-make-dist; \
+	else \
+		python3 build_llm_docs.py --no-make-dist; \
+	fi
+
diff --git a/README-LLM-DOCS.md b/README-LLM-DOCS.md
new file mode 100644
index 00000000..126cca7a
--- /dev/null
+++ b/README-LLM-DOCS.md
@@ -0,0 +1,239 @@
+# LLM-Optimized Documentation Generation
+
+This repository includes a system for generating consolidated, LLM-optimized documentation files from the Hugo-based documentation source. The system produces single-file documentation that is perfect for use with Large Language Models, with all internal links converted to hierarchical references.
+
+## Overview
+
+The documentation pipeline works as follows:
+
+1. **Hugo builds variant-specific markdown** from the source content
+2. **LLM doc builder** consolidates all pages into single files with optimized link processing
+3. **Result**: Clean, searchable, self-contained documentation files for each variant
+
+## Architecture
+
+### Source Content Structure
+```
+content/
+â”œâ”€â”€ user-guide/
+â”‚   â”œâ”€â”€ getting-started/
+â”‚   â”‚   â”œâ”€â”€ index.md
+â”‚   â”‚   â”œâ”€â”€ local-setup.md
+â”‚   â”‚   â””â”€â”€ ...
+â”‚   â”œâ”€â”€ task-configuration/
+â”‚   â””â”€â”€ ...
+â”œâ”€â”€ tutorials/
+â”œâ”€â”€ integrations/
+â””â”€â”€ ...
+```
+
+### Hugo Processing
+The Hugo build system processes the source content using:
+- **Variants**: Different product versions (flyte, byoc, selfmanaged, serverless)
+- **Shortcodes**: Dynamic content insertion based on variants
+- **Templates**: Consistent page structure and navigation
+
+### Generated Output Structure
+```
+dist/docs/v2/
+â”œâ”€â”€ flyte/
+â”‚   â”œâ”€â”€ md/           # Hugo-generated markdown
+â”‚   â””â”€â”€ llms-full.txt # LLM-optimized consolidated doc
+â”œâ”€â”€ byoc/
+â”‚   â”œâ”€â”€ md/
+â”‚   â””â”€â”€ llms-full.txt
+â””â”€â”€ ...
+```
+
+## LLM Documentation Builder (`build_llm_docs.py`)
+
+### Core Features
+
+1. **Depth-First Traversal**: Follows `## Subpages` links in proper hierarchical order
+2. **Hierarchical Link Processing**: Converts all internal links to searchable hierarchical references
+3. **Multi-Variant Support**: Generates separate files for each documentation variant
+4. **Complete Heading Analysis**: Parses all headings to support anchor link resolution
+
+### Processing Pipeline
+
+#### 1. Documentation Regeneration
+```bash
+make dist  # Rebuilds all Hugo variants
+```
+
+#### 2. Variant Discovery
+Automatically discovers available variants in `dist/docs/v2/`
+
+#### 3. Page Traversal
+Starting from `md/index.md`, follows subpage links depth-first:
+```markdown
+## Subpages
+- [User Guide](user-guide/index.md)
+- [Tutorials](tutorials/index.md)
+```
+
+#### 4. Hierarchy Building
+Builds complete page hierarchy as it traverses:
+- `index.md` â†’ "Documentation"
+- `user-guide/index.md` â†’ "Documentation > User Guide"
+- `user-guide/getting-started/local-setup.md` â†’ "Documentation > User Guide > Getting Started > Local Setup"
+
+#### 5. Heading Analysis
+For each page, parses all markdown headings to build anchor lookup:
+```markdown
+# Local Setup                    â†’ Page title (already in hierarchy)
+## Setting up a configuration    â†’ "Getting Started > Local Setup > Setting up a configuration file"
+### Specify explicitly          â†’ "Getting Started > Local Setup > Setting up a configuration file > Specify explicitly"
+```
+
+#### 6. Link Processing
+Converts all internal links to hierarchical references:
+
+**Cross-page links:**
+- `[Local setup](local-setup.md)` â†’ `**Getting started > Local setup**`
+- `[Config](local-setup.md#setting-up-a-configuration-file)` â†’ `**Getting started > Local setup > Setting up a configuration file**`
+
+**Same-page anchor links:**
+- `[Image building](#image-building)` â†’ `**Task configuration > Container images > Image building**`
+
+**Preserved links:**
+- External: `[GitHub](https://github.com/...)` â†’ unchanged
+- Cross-variant: `[Union.ai](/docs/v2/byoc/)` â†’ unchanged
+- Static files: `[notebook.ipynb](/_static/...)` â†’ unchanged
+
+## Usage
+
+### Generating LLM Documentation
+
+Run the build script:
+```bash
+python build_llm_docs.py
+```
+
+This will:
+1. Run `make dist` to regenerate all documentation variants
+2. Process each variant (flyte, byoc, selfmanaged, serverless)
+3. Generate `llms-full.txt` files in each variant directory
+
+### Output Files
+
+Generated files are located at each variant directory:
+- `dist/docs/v2/flyte/llms-full.txt` + `llms.txt`
+- `dist/docs/v2/byoc/llms-full.txt` + `llms.txt`
+- `dist/docs/v2/selfmanaged/llms-full.txt` + `llms.txt`
+- `dist/docs/v2/serverless/llms-full.txt` + `llms.txt`
+
+**Two files per variant:**
+
+1. **`llms-full.txt`** - The complete consolidated documentation:
+   - **Complete documentation** for that variant in depth-first order
+   - **Page delimiters**: `=== PAGE: path/to/file.md ===`
+   - **Hierarchical internal links**: All `.md` and `#anchor` links converted to `**Page > Section**` format
+   - **Preserved external links**: GitHub, cross-variant, and static file links unchanged
+
+2. **`llms.txt`** - A redirect/discovery file:
+   - Brief explanation of the LLM documentation system
+   - Link to the corresponding `llms-full.txt` file
+   - Variant and version information
+   - Usage guidance for LLMs and RAG systems
+
+## Key Implementation Details
+
+### Lookup Table System
+The builder maintains a comprehensive lookup table mapping:
+```
+# Pages
+"user-guide/getting-started/local-setup.md" â†’ "Getting Started > Local Setup"
+
+# Anchors
+"local-setup.md#using-the-configuration-file" â†’ "Getting Started > Local Setup > Using the configuration file"
+```
+
+### Anchor Generation
+Heading titles are converted to URL anchors using standard rules:
+- Lowercase conversion
+- Space to hyphen replacement
+- Special character removal
+- Example: "Setting up a Configuration File" â†’ "setting-up-a-configuration-file"
+
+### Hierarchy Optimization
+The system automatically strips redundant prefixes:
+- Raw: "Documentation > Flyte > Getting Started > Local Setup"
+- Optimized: "Getting Started > Local Setup" (in flyte variant)
+
+This keeps references concise while maintaining uniqueness within each variant.
+
+### Error Handling
+- **Missing files**: Warnings logged, processing continues
+- **Broken links**: Fallback to link text with current context
+- **Invalid anchors**: Graceful fallback to text-based reference
+
+## Benefits for LLM Usage
+
+### Perfect Internal References
+- âœ… **No broken links**: All internal `.md` references point to content in the same file
+- âœ… **Searchable**: LLMs can find any referenced content by searching hierarchical titles
+- âœ… **Context-rich**: Every reference includes full page and section hierarchy
+- âœ… **Consistent format**: All internal references follow `**Page > Section**` pattern
+
+### Complete Content
+- âœ… **Single file**: All documentation in one consolidated file per variant
+- âœ… **Proper order**: Content follows logical depth-first navigation structure
+- âœ… **No duplication**: Each page appears exactly once in the correct hierarchical position
+
+### LLM-Friendly Format
+- âœ… **Clear delimiters**: Easy to identify page boundaries
+- âœ… **Hierarchical structure**: Matches how humans think about documentation organization
+- âœ… **No file system dependencies**: All references are text-based within the same document
+
+## Example Output
+
+```markdown
+=== PAGE: user-guide/getting-started/local-setup.md ===
+
+# Local Setup
+
+Before proceeding, make sure you have completed the steps in **Getting started**.
+
+Use the **Getting started > `flyte create config`** command, making the following changes:
+
+See **Getting started > Local setup > Setting up a configuration file** for details.
+
+## Setting up a configuration file
+
+You can also reference **Task configuration > Container images > Image building** for advanced setup.
+
+=== PAGE: user-guide/getting-started/running.md ===
+
+# Running Your First Task
+
+...
+```
+
+## Maintenance
+
+### Updating the System
+The LLM documentation builder automatically regenerates content from the current Hugo source. To update:
+
+1. **Content changes**: Modify files in `content/` directory
+2. **Regenerate**: Run `python build_llm_docs.py`
+3. **New files**: Added automatically if linked via `## Subpages`
+
+### Adding New Variants
+New Hugo variants are automatically detected and processed. No code changes required.
+
+### Debugging
+- Enable verbose output by checking the console during build
+- Inspect generated `md/` directories to verify Hugo processing
+- Check file sizes - significant changes may indicate processing issues
+
+## Integration
+
+The LLM documentation files can be used with:
+- **Vector databases** for semantic search
+- **RAG systems** for question answering
+- **AI assistants** for documentation support
+- **API documentation tools** that consume markdown
+- **Training datasets** for domain-specific models
+
+The hierarchical link structure ensures that LLMs can accurately reference and cross-reference content without confusion about file paths or broken links.
\ No newline at end of file
diff --git a/README.md b/README.md
index 2e27fe72..b500506c 100644
--- a/README.md
+++ b/README.md
@@ -8,4 +8,6 @@ This repository holds all documentation for the [Flyte OSS project](https://www.
 
 Details on how to author, build and publish the docs can be found on the website itself at [Contributing docs and examples](https://union.ai/docs/flyte/community/contributing-docs).
 
+<!-- Trigger Cloudflare build - Dec 5, 2025 -->
+
 The source code for that section can be found in this repository under `content/community/contributing-docs/`.
diff --git a/build.sh b/build.sh
new file mode 100755
index 00000000..1c17044a
--- /dev/null
+++ b/build.sh
@@ -0,0 +1,32 @@
+#!/bin/bash
+
+# Cloudflare Pages build script
+# This script ensures Python dependencies are available and runs the full build process
+
+set -e
+
+echo "=== Cloudflare Pages Build Script ==="
+echo "Current directory: $(pwd)"
+echo "Python version: $(python3 --version)"
+echo "Node version: $(node --version)"
+
+# Install Python dependencies
+echo "Installing Python dependencies..."
+pip3 install toml
+
+# Verify dependencies
+echo "Verifying Python dependencies..."
+python3 -c "import toml; print('toml version:', toml.__version__)"
+
+# Run the build process
+echo "Running make dist..."
+make dist
+
+echo "Build completed successfully!"
+echo "Generated files:"
+ls -la dist/
+
+# Copy dist directory to Cloudflare Pages output
+echo "Preparing output for Cloudflare Pages..."
+# Cloudflare Pages expects output in the root directory or a specific output directory
+# The dist/ directory contains our built site
\ No newline at end of file
diff --git a/build_llm_docs.py b/build_llm_docs.py
new file mode 100755
index 00000000..dccd76dd
--- /dev/null
+++ b/build_llm_docs.py
@@ -0,0 +1,659 @@
+#!/usr/bin/env python3
+"""
+Simple script to build consolidated LLM-optimized documents by following ## Subpages links
+in depth-first order starting from md/index.md.
+
+Usage: python build_llm_docs.py
+"""
+
+import os
+import re
+import subprocess
+from pathlib import Path
+from typing import Set, List
+
+class LLMDocBuilder:
+    def __init__(self, base_path: Path):
+        self.base_path = base_path
+        self.visited_files: Set[str] = set()
+        self.title_lookup: dict[str, str] = {}  # Maps file paths to hierarchical titles
+
+    def run_make_dist(self) -> bool:
+        """Run make dist to regenerate all documentation variants."""
+        print("ðŸ”§ Running 'make dist' to regenerate documentation...")
+        try:
+            result = subprocess.run(['make', 'dist'],
+                                  cwd=self.base_path,
+                                  capture_output=True,
+                                  text=True,
+                                  timeout=300)
+            if result.returncode == 0:
+                print("âœ… Successfully regenerated documentation")
+                return True
+            else:
+                print(f"âŒ Make dist failed with return code {result.returncode}")
+                return False
+        except Exception as e:
+            print(f"âŒ Error running make dist: {e}")
+            return False
+
+    def read_file_content(self, file_path: Path) -> str:
+        """Read and clean markdown file content."""
+        try:
+            with open(file_path, 'r', encoding='utf-8') as f:
+                content = f.read()
+
+            # Remove the footer metadata section
+            content = re.sub(r'\n---\n\*\*Source\*\*:.*?(?=\n\n|\Z)', '', content, flags=re.DOTALL)
+
+            # This will be updated in process_page_depth_first to pass hierarchy
+            # content = self.process_internal_links(content, file_path, hierarchy)
+
+            # Clean up excessive whitespace but preserve structure
+            content = content.rstrip() + '\n'
+
+            return content
+        except Exception as e:
+            print(f"âŒ Error reading {file_path}: {e}")
+            return ""
+
+    def process_internal_links(self, content: str, current_file_path: Path, current_hierarchy: List[str]) -> str:
+        """Convert internal documentation links to hierarchical bold references."""
+        def replace_internal_link(match):
+            text = match.group(1)
+            url = match.group(2)
+
+            # Keep external links unchanged
+            if url.startswith(('http://', 'https://', 'mailto:')):
+                return match.group(0)
+
+            # Convert same-page anchor links to hierarchical references
+            if url.startswith('#'):
+                anchor = url[1:]  # Remove the # prefix
+                anchor_key = f"{current_file_path.name}#{anchor}"
+                if anchor_key in self.title_lookup:
+                    hierarchical_title = self.title_lookup[anchor_key]
+                    return f"**{hierarchical_title}**"
+                # Fallback: use current page hierarchy + link text
+                else:
+                    current_page_title = self.strip_common_prefix(' > '.join(current_hierarchy))
+                    return f"**{current_page_title} > {text}**"
+
+            # For internal .md links (with or without anchors), convert to hierarchical reference
+            if '.md' in url and not url.startswith(('http://', 'https://')):
+                hierarchical_title = self.resolve_hierarchical_title(url, current_file_path, current_hierarchy, text)
+                return f"**{hierarchical_title}**"
+
+            # Keep other links unchanged (absolute paths like /docs/, static files, etc.)
+            return match.group(0)
+
+        # Process markdown links
+        content = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', replace_internal_link, content)
+        return content
+
+    def resolve_hierarchical_title(self, url: str, current_file_path: Path, current_hierarchy: List[str], link_text: str) -> str:
+        """Resolve hierarchical title using lookup table."""
+        # Resolve the target file path
+        target_path = self.resolve_link_path(url, current_file_path)
+
+        # Look up in our title mapping
+        if target_path in self.title_lookup:
+            title = self.title_lookup[target_path]
+            # Skip "Documentation > {VARIANT}" prefix
+            return self.strip_common_prefix(title)
+
+        # Fallback: use current hierarchy + link text (also strip prefix)
+        if current_hierarchy:
+            full_title = f"{' > '.join(current_hierarchy)} > {link_text}"
+            return self.strip_common_prefix(full_title)
+
+        return link_text
+
+    def strip_common_prefix(self, title: str) -> str:
+        """Remove 'Documentation > {variant}' prefix from hierarchical titles."""
+        parts = title.split(' > ')
+        # Skip first two parts if they match the expected pattern
+        if len(parts) >= 2 and parts[0] == 'Documentation':
+            return ' > '.join(parts[2:]) if len(parts) > 2 else parts[-1]
+        return title
+
+    def resolve_link_path(self, url: str, current_file_path: Path) -> str:
+        """Resolve a relative URL to an absolute path key."""
+        # Split URL and anchor
+        if '#' in url:
+            file_part, anchor = url.split('#', 1)
+        else:
+            file_part, anchor = url, None
+
+        try:
+            # Handle relative paths
+            if file_part.startswith('../') or file_part.startswith('./'):
+                resolved = (current_file_path.parent / file_part).resolve()
+            elif file_part:  # Non-empty file part
+                resolved = (current_file_path.parent / file_part).resolve()
+            else:  # Just anchor, same file
+                resolved = current_file_path
+
+            # Convert to lookup key
+            key = str(resolved.name)
+            if anchor:
+                key = f"{key}#{anchor}"
+
+            return key
+        except:
+            return url
+
+    def extract_page_title(self, content: str, file_path: Path) -> str:
+        """Extract the main title from a markdown page."""
+        # Look for the first # title
+        title_match = re.search(r'^#\s+(.+?)\s*$', content, re.MULTILINE)
+        if title_match:
+            return title_match.group(1).strip()
+
+        # Fallback to filename
+        name = file_path.stem
+        if name == 'index':
+            name = file_path.parent.name
+        return name.replace('-', ' ').replace('_', ' ').title()
+
+    def parse_heading_hierarchy(self, content: str, file_path: Path, page_hierarchy: List[str]) -> dict[str, str]:
+        """Parse all headings and build anchor lookup table."""
+        anchor_map = {}
+
+        # Find all markdown headings
+        heading_pattern = r'^(#{1,6})\s+(.+?)\s*$'
+        headings = []
+
+        for match in re.finditer(heading_pattern, content, re.MULTILINE):
+            level = len(match.group(1))  # Number of # characters
+            title = match.group(2).strip()
+            anchor = self.title_to_anchor(title)
+            headings.append((level, title, anchor))
+
+        # Build hierarchical structure
+        heading_stack = []  # Stack to track current hierarchy
+
+        for level, title, anchor in headings:
+            # Skip the main page title (# heading) since it's already in page_hierarchy
+            if level == 1:
+                heading_stack = [(level, title)]  # Reset stack with main title
+                # Don't add to anchor_map for level 1 headings since they duplicate page title
+                continue
+
+            # Pop headings that are at same or deeper level
+            while heading_stack and heading_stack[-1][0] >= level:
+                heading_stack.pop()
+
+            # Add current heading to stack
+            heading_stack.append((level, title))
+
+            # Build full hierarchical title - skip the first heading in stack (main title)
+            heading_hierarchy = [h[1] for h in heading_stack[1:]]  # Skip first element
+            full_hierarchy = page_hierarchy + heading_hierarchy
+            hierarchical_title = ' > '.join(full_hierarchy)
+
+            # Store in anchor map (strip common prefix)
+            clean_title = self.strip_common_prefix(hierarchical_title)
+            anchor_map[anchor] = clean_title
+
+        return anchor_map
+
+    def title_to_anchor(self, title: str) -> str:
+        """Convert heading title to URL anchor format."""
+        # Convert to lowercase, replace spaces with hyphens, remove special chars
+        anchor = re.sub(r'[^a-zA-Z0-9\s-]', '', title)
+        anchor = re.sub(r'\s+', '-', anchor.strip().lower())
+        return anchor
+
+    def extract_subpage_links(self, content: str) -> List[str]:
+        """Extract links from ## Subpages section."""
+        # Find the ## Subpages section
+        subpages_pattern = r'## Subpages\s*\n(.*?)(?=\n##|\n---|\Z)'
+        match = re.search(subpages_pattern, content, re.DOTALL | re.IGNORECASE)
+
+        if not match:
+            return []
+
+        subpages_content = match.group(1).strip()
+
+        # Extract markdown links
+        links = []
+        link_pattern = r'- \[([^\]]+)\]\(([^)]+)\)'
+
+        for link_match in re.finditer(link_pattern, subpages_content):
+            link_url = link_match.group(2)
+            # Clean the URL (remove anchors, etc.)
+            link_url = link_url.split('#')[0].strip()
+            if link_url and not link_url.startswith(('http://', 'https://')):
+                links.append(link_url)
+
+        return links
+
+    def build_consolidated_doc(self, variant: str, version: str = 'v2') -> str:
+        """Build consolidated document by following subpage links depth-first."""
+        md_dir = self.base_path / 'dist' / 'docs' / version / variant / 'md'
+
+        if not md_dir.exists():
+            print(f"âŒ Directory not found: {md_dir}")
+            return ""
+
+        print(f"ðŸ“– Building consolidated document for {variant}")
+        consolidated_content = []
+
+        # Start with index.md
+        self.process_page_depth_first(md_dir, 'index.md', consolidated_content, md_dir, [])
+
+        return '\n'.join(consolidated_content)
+
+    def process_page_depth_first(self, base_dir: Path, relative_path: str,
+                                consolidated: List[str], md_root: Path, hierarchy: List[str] = None):
+        """Process a page and its subpages in depth-first order."""
+
+        if hierarchy is None:
+            hierarchy = []
+
+        # Resolve the full path
+        if relative_path.endswith('/'):
+            file_path = base_dir / relative_path / 'index.md'
+            relative_path = relative_path + 'index.md'
+        elif not relative_path.endswith('.md'):
+            # Try both with and without .md extension
+            if (base_dir / f"{relative_path}.md").exists():
+                file_path = base_dir / f"{relative_path}.md"
+                relative_path = f"{relative_path}.md"
+            elif (base_dir / relative_path / 'index.md').exists():
+                file_path = base_dir / relative_path / 'index.md'
+                relative_path = f"{relative_path}/index.md"
+            else:
+                print(f"âš ï¸  Could not find file for: {relative_path}")
+                return
+        else:
+            file_path = base_dir / relative_path        # Avoid infinite loops
+        canonical_path = str(file_path.resolve())
+        if canonical_path in self.visited_files:
+            return
+        self.visited_files.add(canonical_path)
+
+        if not file_path.exists():
+            print(f"âš ï¸  File not found: {file_path}")
+            return
+
+        # Get relative path from md root for the delimiter
+        try:
+            relative_from_md = str(file_path.relative_to(md_root))
+        except ValueError:
+            relative_from_md = str(file_path)
+
+        print(f"  ðŸ“„ Processing: {relative_from_md}")
+
+        # Read the raw content
+        raw_content = self.read_file_content(file_path)
+        if not raw_content.strip():
+            return
+
+        # Extract page title and build hierarchy
+        page_title = self.extract_page_title(raw_content, file_path)
+        current_hierarchy = hierarchy + [page_title]
+        hierarchical_title = ' > '.join(current_hierarchy)
+
+        # Store page in lookup table
+        self.title_lookup[relative_from_md] = hierarchical_title
+        self.title_lookup[file_path.name] = hierarchical_title  # Also store by filename
+
+        # Parse and store heading hierarchy for anchor links
+        anchor_map = self.parse_heading_hierarchy(raw_content, file_path, current_hierarchy)
+        for anchor, anchor_title in anchor_map.items():
+            # Store with full file path + anchor
+            anchor_key = f"{relative_from_md}#{anchor}"
+            self.title_lookup[anchor_key] = anchor_title
+
+            # Also store with just filename + anchor for relative links
+            filename_key = f"{file_path.name}#{anchor}"
+            self.title_lookup[filename_key] = anchor_title
+
+        # Extract subpages BEFORE processing links (so links don't break extraction)
+        subpage_links = self.extract_subpage_links(raw_content)
+
+        # NOW process internal links with hierarchy context
+        content = self.process_internal_links(raw_content, file_path, current_hierarchy)
+
+        # Add page delimiter
+        consolidated.append(f"\n=== PAGE: {relative_from_md} ===\n")
+        consolidated.append(content)
+
+        # Process subpages depth-first
+        for link in subpage_links:
+            print(f"    ðŸ”— Following: {link}")
+            # Resolve relative to the current file's directory
+            current_dir = file_path.parent
+            self.process_page_depth_first(current_dir, link, consolidated, md_root, current_hierarchy)
+
+    def find_variants(self) -> List[str]:
+        """Find available variants in the dist directory."""
+        dist_path = self.base_path / "dist" / "docs" / "v2"
+        if not dist_path.exists():
+            return []
+
+        variants = []
+        for item in dist_path.iterdir():
+            if item.is_dir() and (item / 'md').exists():
+                variants.append(item.name)
+
+        return sorted(variants)
+
+    def create_redirect_content(self, variant: str) -> str:
+        """Create content for the redirect llms.txt file."""
+        variant_names = {
+            'flyte': 'Flyte Open Source',
+            'byoc': 'Union.ai BYOC (Bring Your Own Cloud)',
+            'selfmanaged': 'Union.ai Self-managed',
+            'serverless': 'Union.ai Serverless'
+        }
+
+        variant_display = variant_names.get(variant, variant.title())
+
+        return f"""# {variant_display} Documentation (LLM-Optimized)
+
+This is the LLM-optimized documentation redirect for **{variant_display}** (version 2).
+
+## Full Documentation
+
+For the complete consolidated documentation optimized for Large Language Models, see:
+
+ðŸ‘‰ **[llms-full.txt](llms-full.txt)**
+
+The `llms-full.txt` file contains:
+- Complete {variant_display} documentation in a single file
+- All internal links converted to hierarchical references (e.g., `**Getting started > Local setup**`)
+- Depth-first page organization following the documentation structure
+- Perfect format for LLM consumption, RAG systems, and vector databases
+
+## File Details
+
+- **Variant**: {variant}
+- **Version**: v2
+- **Format**: LLM-optimized consolidated markdown
+- **Size**: ~1.4MB+ of comprehensive documentation
+- **Update frequency**: Generated automatically from source documentation
+
+## Usage
+
+This consolidated documentation is ideal for:
+- Large Language Model context and training
+- RAG (Retrieval-Augmented Generation) systems
+- Vector database ingestion
+- AI assistants and chatbots
+- Automated documentation analysis
+
+---
+
+*Generated automatically from the Union.ai documentation system.*
+"""
+
+    def create_discovery_files(self, base_path: Path, variants: List[str]) -> None:
+        """Create hierarchical discovery files for LLM documentation."""
+
+        # Root level discovery file (/docs/llms.txt)
+        root_content = self.create_root_discovery_content(variants)
+        root_file = base_path / 'dist' / 'docs' / 'llms.txt'
+
+        with open(root_file, 'w', encoding='utf-8') as f:
+            f.write(root_content)
+        print(f"âœ… Created root discovery: {root_file}")
+
+        # Version level discovery file (/docs/v2/llms.txt)
+        v2_content = self.create_version_discovery_content(variants, 'v2')
+        v2_file = base_path / 'dist' / 'docs' / 'v2' / 'llms.txt'
+
+        with open(v2_file, 'w', encoding='utf-8') as f:
+            f.write(v2_content)
+        print(f"âœ… Created v2 discovery: {v2_file}")
+
+    def create_root_discovery_content(self, variants: List[str]) -> str:
+        """Create content for the root-level discovery file."""
+        variant_names = {
+            'flyte': 'Flyte Open Source',
+            'byoc': 'Union.ai BYOC (Bring Your Own Cloud)',
+            'selfmanaged': 'Union.ai Self-managed',
+            'serverless': 'Union.ai Serverless'
+        }
+
+        variant_descriptions = {
+            'flyte': 'Free and open source workflow orchestration platform',
+            'byoc': 'Commercial Union.ai product - bring your own cloud infrastructure',
+            'selfmanaged': 'Commercial Union.ai product - fully managed deployment',
+            'serverless': 'Commercial Union.ai product - serverless execution'
+        }
+
+        # All four variants for both versions
+        all_variants = ['byoc', 'flyte', 'selfmanaged', 'serverless']
+
+        # V2 variant links (current variants)
+        v2_variant_links = []
+        for variant in sorted(variants):
+            name = variant_names.get(variant, variant.title())
+            desc = variant_descriptions.get(variant, f'{variant.title()} variant documentation')
+            v2_variant_links.append(f"  - **[{name}](v2/{variant}/llms-full.txt)** - {desc}")
+
+        # V1 variant links (all four variants)
+        v1_variant_links = []
+        for variant in sorted(all_variants):
+            name = variant_names.get(variant, variant.title())
+            desc = variant_descriptions.get(variant, f'{variant.title()} variant documentation')
+            v1_variant_links.append(f"  - **[{name}](v1/{variant}/llms-full.txt)** - {desc}")
+
+        return f"""# Union.ai Documentation (LLM-Optimized)
+
+This is the root discovery file for LLM-optimized documentation across all Union.ai and Flyte products.
+
+## Available Documentation
+
+### Version 2 (Current)
+
+All documentation variants for **Version 2** (current):
+
+{chr(10).join(v2_variant_links)}
+
+**Version-level overview**: [v2/llms.txt](v2/llms.txt) - All v2 variants with detailed descriptions
+
+### Version 1 (Legacy)
+
+All documentation variants for **Version 1** (legacy):
+
+{chr(10).join(v1_variant_links)}
+
+**Version-level overview**: [v1/llms.txt](v1/llms.txt) - All v1 variants with detailed descriptions
+
+## Navigation Guide
+
+### For LLMs and RAG Systems
+1. **Direct access**: Use the direct links above to access specific variant documentation
+2. **Version browsing**: Use `v2/llms.txt` for detailed v2 variant information
+3. **Variant browsing**: Use `v2/{variant}/llms.txt` for specific variant details
+
+### Documentation Structure
+- **Root** (`/docs/llms.txt`) - This file, overview of all versions and variants
+- **Version** (`/docs/v2/llms.txt`) - All variants for version 2
+- **Variant** (`/docs/v2/{variant}/llms.txt`) - Redirect to specific consolidated documentation
+- **Content** (`/docs/v2/{variant}/llms-full.txt`) - Complete consolidated documentation
+
+## File Characteristics
+
+Each `llms-full.txt` file contains:
+- **Complete documentation** for that variant (~1.4MB+ each)
+- **Hierarchical internal links** - All `.md` and `#anchor` links converted to searchable references
+- **Depth-first organization** - Content follows logical navigation structure
+- **LLM-optimized format** - Perfect for RAG systems, vector databases, and AI assistants
+
+## Product Information
+
+- **Flyte**: Open source workflow orchestration platform maintained by Union.ai
+- **Union.ai Products**: Commercial offerings built on Flyte with additional enterprise features
+- **Version 2**: Current generation with pure Python execution and simplified API
+- **All variants**: Share core Flyte functionality with product-specific enhancements
+
+---
+
+*Generated automatically from the Union.ai documentation system.*
+*Last updated: {self.get_current_timestamp()}*
+"""
+
+    def create_version_discovery_content(self, variants: List[str], version: str) -> str:
+        """Create content for version-level discovery file."""
+        variant_names = {
+            'flyte': 'Flyte Open Source',
+            'byoc': 'Union.ai BYOC (Bring Your Own Cloud)',
+            'selfmanaged': 'Union.ai Self-managed',
+            'serverless': 'Union.ai Serverless'
+        }
+
+        variant_details = {
+            'flyte': {
+                'desc': 'Free and open source workflow orchestration platform',
+                'features': ['Pure Python execution', 'Local development', 'Self-hosted deployment', 'Community support'],
+                'audience': 'Developers, data scientists, ML engineers using open source tools'
+            },
+            'byoc': {
+                'desc': 'Commercial Union.ai product with your cloud infrastructure',
+                'features': ['All Flyte features', 'Reusable containers', 'Enterprise support', 'Multi-cluster management'],
+                'audience': 'Enterprises with existing cloud infrastructure and compliance requirements'
+            },
+            'selfmanaged': {
+                'desc': 'Commercial Union.ai product with managed infrastructure',
+                'features': ['All BYOC features', 'Fully managed deployment', 'Union.ai infrastructure', 'SLA guarantees'],
+                'audience': 'Teams wanting managed infrastructure without operational overhead'
+            },
+            'serverless': {
+                'desc': 'Commercial Union.ai product with serverless execution',
+                'features': ['All Union.ai features', 'Pay-per-execution', 'Zero infrastructure management', 'Auto-scaling'],
+                'audience': 'Teams with variable workloads and minimal infrastructure requirements'
+            }
+        }
+
+        variant_sections = []
+        for variant in sorted(variants):
+            name = variant_names.get(variant, variant.title())
+            details = variant_details.get(variant, {
+                'desc': f'{variant.title()} variant documentation',
+                'features': ['Core Flyte functionality'],
+                'audience': 'General users'
+            })
+
+            features_list = '\n'.join([f'  - {feature}' for feature in details['features']])
+
+            variant_sections.append(f"""### {name}
+
+**Description**: {details['desc']}
+
+**Key Features**:
+{features_list}
+
+**Target Audience**: {details['audience']}
+
+**Documentation**:
+- **[{variant}/llms.txt]({variant}/llms.txt)** - Variant-specific redirect and information
+- **[{variant}/llms-full.txt]({variant}/llms-full.txt)** - Complete consolidated documentation (~1.4MB+)""")
+
+        return f"""# Version {version.upper()} Documentation (LLM-Optimized)
+
+This is the version-level discovery file for all **Version {version.upper()}** documentation variants.
+
+## Available Variants
+
+{chr(10).join(variant_sections)}
+
+## Navigation
+
+- **[Root Documentation](../llms.txt)** - Overview of all versions and variants
+- **Individual Variants** - Use the links above to access specific variant documentation
+- **Direct Access** - Use `{variant}/llms-full.txt` URLs for direct LLM consumption
+
+## Version {version.upper()} Overview
+
+Version {version.upper()} represents the current generation of Flyte and Union.ai products, featuring:
+- **Pure Python execution** - No more YAML workflows or complex decorators
+- **Simplified API** - Intuitive task definition and execution patterns
+- **Enhanced local development** - Seamless transition from local to remote execution
+- **Native notebook support** - First-class Jupyter integration
+- **Improved observability** - Fine-grained tracing and monitoring
+
+## For LLMs and RAG Systems
+
+Each consolidated documentation file is specifically optimized for AI consumption:
+- **No broken links** - All internal references converted to hierarchical text
+- **Complete content** - Single file contains all documentation for that variant
+- **Searchable structure** - Hierarchical references like `**Getting started > Local setup**`
+- **Consistent format** - Standardized page delimiters and link processing
+
+## Usage Examples
+
+```
+# Access specific variant documentation
+GET /docs/v2/flyte/llms-full.txt
+GET /docs/v2/byoc/llms-full.txt
+
+# Get variant information and redirect
+GET /docs/v2/flyte/llms.txt
+GET /docs/v2/byoc/llms.txt
+```
+
+---
+
+*Generated automatically from the Union.ai documentation system.*
+*Last updated: {self.get_current_timestamp()}*
+"""
+
+    def get_current_timestamp(self) -> str:
+        """Get current timestamp for documentation."""
+        from datetime import datetime
+        return datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC")
+
+def main():
+    import sys
+    base_path = Path.cwd()
+    builder = LLMDocBuilder(base_path)
+
+    # Step 1: Regenerate documentation (skip if --no-make-dist is passed)
+    if '--no-make-dist' not in sys.argv and not builder.run_make_dist():
+        return 1
+
+    # Step 2: Find variants
+    variants = builder.find_variants()
+    if not variants:
+        print("âŒ No variants found")
+        return 1
+
+    print(f"ðŸ“‹ Found variants: {variants}")
+
+    # Step 3: Build consolidated documents
+    for variant in variants:
+        consolidated_content = builder.build_consolidated_doc(variant)
+
+        if consolidated_content.strip():
+            # Create output file
+            output_file = base_path / 'dist' / 'docs' / 'v2' / variant / 'llms-full.txt'
+
+            with open(output_file, 'w', encoding='utf-8') as f:
+                f.write(consolidated_content)
+
+            file_size = len(consolidated_content)
+            print(f"âœ… Saved: {output_file} ({file_size:,} characters)")
+
+            # Create redirect llms.txt file
+            redirect_file = base_path / 'dist' / 'docs' / 'v2' / variant / 'llms.txt'
+            redirect_content = builder.create_redirect_content(variant)
+
+            with open(redirect_file, 'w', encoding='utf-8') as f:
+                f.write(redirect_content)
+
+            print(f"âœ… Created redirect: {redirect_file}")
+        else:
+            print(f"âŒ No content generated for {variant}")
+
+    # Step 4: Create hierarchical discovery files
+    builder.create_discovery_files(base_path, variants)
+
+    return 0
+
+if __name__ == '__main__':
+    exit(main())
\ No newline at end of file
diff --git a/consolidated_byoc_docs.md b/consolidated_byoc_docs.md
new file mode 100644
index 00000000..a3ae0e1d
--- /dev/null
+++ b/consolidated_byoc_docs.md
@@ -0,0 +1,498 @@
+# Documentation
+**Variant:** byoc  
+**Generated:** 2025-12-05
+
+This is a consolidated view of all documentation pages in hierarchical order.
+
+# Documentation
+
+Welcome to the documentation.
+
+## Subpages
+
+- [User Guide](user-guide/index.md)
+- [Tutorials](tutorials/index.md)
+- [Integrations](integrations/index.md)
+- [API Reference](api-reference/index.md)
+- [Community](community/index.md)
+- [Release Notes](release-notes.md)
+
+---
+**PAGE: User Guide**
+**SOURCE: user-guide/index.md**
+
+
+# Union.ai BYOC
+
+Union.ai empowers AI development teams to rapidly ship high-quality code to production by offering optimized performance, unparalleled resource efficiency, and a delightful workflow authoring experience. With Union.ai your team can:
+
+* Run complex AI workloads with performance, scale, and efficiency.
+* Achieve millisecond-level execution times with reusable containers.
+* Scale out to multiple regions, clusters, and clouds as needed for resource availability, scale, or compliance.
+
+> [!NOTE]
+> These are the Union.ai **2.0 beta** docs.
+> To switch to [version 1.0](/docs/v1/byoc/) or to another product variant, use the selectors above.
+>
+> Union.ai is built on top of the leading open-source workflow orchestrator, [Flyte](/docs/v2/flyte/).
+>
+> Union.ai BYOC (Bring Your Own Cloud) provides all the features of Flyte, plus much more
+> in an environment where you keep your data and workflow code on your infrastructure, while Union.ai takes care of the management.
+
+### ðŸ’¡ [Flyte 2](flyte-2/index.md)
+
+Flyte 2 represents a fundamental shift in how AI workflows are written and executed. Learn
+more in this section.
+
+### ðŸ”¢ [Getting started](getting-started/index.md)
+
+Install Flyte 2, configure your local IDE, create and run your first task, and inspect the results in 2 minutes.
+
+## Subpages
+- [Flyte 2](flyte-2/index.md)
+- [Getting started](getting-started/index.md)
+- [Task configuration](task-configuration/index.md)
+- [Task programming](task-programming/index.md)
+- [Considerations](considerations.md)
+
+---
+**PAGE: User Guide**
+**SOURCE: user-guide/index.md**
+
+
+# Union.ai BYOC
+
+Union.ai empowers AI development teams to rapidly ship high-quality code to production by offering optimized performance, unparalleled resource efficiency, and a delightful workflow authoring experience. With Union.ai your team can:
+
+* Run complex AI workloads with performance, scale, and efficiency.
+* Achieve millisecond-level execution times with reusable containers.
+* Scale out to multiple regions, clusters, and clouds as needed for resource availability, scale, or compliance.
+
+> [!NOTE]
+> These are the Union.ai **2.0 beta** docs.
+> To switch to [version 1.0](/docs/v1/byoc/) or to another product variant, use the selectors above.
+>
+> Union.ai is built on top of the leading open-source workflow orchestrator, [Flyte](/docs/v2/flyte/).
+>
+> Union.ai BYOC (Bring Your Own Cloud) provides all the features of Flyte, plus much more
+> in an environment where you keep your data and workflow code on your infrastructure, while Union.ai takes care of the management.
+
+### ðŸ’¡ [Flyte 2](flyte-2/index.md)
+
+Flyte 2 represents a fundamental shift in how AI workflows are written and executed. Learn
+more in this section.
+
+### ðŸ”¢ [Getting started](getting-started/index.md)
+
+Install Flyte 2, configure your local IDE, create and run your first task, and inspect the results in 2 minutes.
+
+## Subpages
+- [Flyte 2](flyte-2/index.md)
+- [Getting started](getting-started/index.md)
+- [Task configuration](task-configuration/index.md)
+- [Task programming](task-programming/index.md)
+- [Considerations](considerations.md)
+
+---
+**PAGE: Tutorials**
+**SOURCE: tutorials/index.md**
+
+
+# Tutorials
+
+This section contains tutorials that showcase relevant use cases and provide step-by-step instructions on how to implement various features using Flyte and Union.
+
+### ðŸ”— [Multi-agent trading simulation](trading-agents.md)
+
+A multi-agent trading simulation, modeling how agents within a firm might interact, strategize, and make trades collaboratively.
+
+### ðŸ”— [Run LLM-generated code](code-agent.md)
+
+Securely execute and iterate on LLM-generated code using a code agent with error reflection and retry logic.
+
+### ðŸ”— [Deep research](deep-research.md)
+
+Build an agentic workflow for deep research with multi-step reasoning and evaluation.
+
+### ðŸ”— [Hyperparameter optimization](hpo.md)
+
+Run large-scale HPO experiments with zero manual tracking, deterministic results, and automatic recovery.
+
+### ðŸ”— [Automatic prompt engineering](auto_prompt_engineering.md)
+
+Easily run prompt optimization with real-time observability, traceability, and automatic recovery.
+
+### ðŸ”— [Text-to-SQL](text_to_sql.md)
+
+Learn how to turn natural language questions into SQL queries with Flyte and LlamaIndex, and explore prompt optimization in practice.
+
+## Subpages
+- [Automatic prompt engineering](auto_prompt_engineering.md)
+- [Deep research](deep-research.md)
+- [Hyperparameter optimization](hpo.md)
+- [Multi-agent trading simulation](trading-agents.md)
+- [Run LLM-generated code](code-agent.md)
+- [Text-to-SQL](text_to_sql.md)
+
+---
+**PAGE: Tutorials**
+**SOURCE: tutorials/index.md**
+
+
+# Tutorials
+
+This section contains tutorials that showcase relevant use cases and provide step-by-step instructions on how to implement various features using Flyte and Union.
+
+### ðŸ”— [Multi-agent trading simulation](trading-agents.md)
+
+A multi-agent trading simulation, modeling how agents within a firm might interact, strategize, and make trades collaboratively.
+
+### ðŸ”— [Run LLM-generated code](code-agent.md)
+
+Securely execute and iterate on LLM-generated code using a code agent with error reflection and retry logic.
+
+### ðŸ”— [Deep research](deep-research.md)
+
+Build an agentic workflow for deep research with multi-step reasoning and evaluation.
+
+### ðŸ”— [Hyperparameter optimization](hpo.md)
+
+Run large-scale HPO experiments with zero manual tracking, deterministic results, and automatic recovery.
+
+### ðŸ”— [Automatic prompt engineering](auto_prompt_engineering.md)
+
+Easily run prompt optimization with real-time observability, traceability, and automatic recovery.
+
+### ðŸ”— [Text-to-SQL](text_to_sql.md)
+
+Learn how to turn natural language questions into SQL queries with Flyte and LlamaIndex, and explore prompt optimization in practice.
+
+## Subpages
+- [Automatic prompt engineering](auto_prompt_engineering.md)
+- [Deep research](deep-research.md)
+- [Hyperparameter optimization](hpo.md)
+- [Multi-agent trading simulation](trading-agents.md)
+- [Run LLM-generated code](code-agent.md)
+- [Text-to-SQL](text_to_sql.md)
+
+---
+**PAGE: Integrations**
+**SOURCE: integrations/index.md**
+
+
+# Integrations
+
+Flyte is designed to be highly extensible and can be customized
+in multiple ways.
+
+## Flyte Plugins
+
+Flyte plugins extend the functionality of the `flyte` SDK.
+
+| Plugin | Description |
+| ------ | ----------- |
+| [Ray](flyte-plugins/ray.md) | Run Ray jobs on your Flyte cluster |
+| [Spark](flyte-plugins/spark.md) | Run Spark jobs on your Flyte cluster |
+| [OpenAI](flyte-plugins/openai/index.md) | Integrate with OpenAI SDKs in your Flyte workflows |
+| [Dask](flyte-plugins/dask.md) | Run Dask jobs on your Flyte cluster |
+
+## Subpages
+- [Connectors](connectors.md)
+- [Flyte plugins](flyte-plugins/index.md)
+
+---
+**PAGE: Integrations**
+**SOURCE: integrations/index.md**
+
+
+# Integrations
+
+Flyte is designed to be highly extensible and can be customized
+in multiple ways.
+
+## Flyte Plugins
+
+Flyte plugins extend the functionality of the `flyte` SDK.
+
+| Plugin | Description |
+| ------ | ----------- |
+| [Ray](flyte-plugins/ray.md) | Run Ray jobs on your Flyte cluster |
+| [Spark](flyte-plugins/spark.md) | Run Spark jobs on your Flyte cluster |
+| [OpenAI](flyte-plugins/openai/index.md) | Integrate with OpenAI SDKs in your Flyte workflows |
+| [Dask](flyte-plugins/dask.md) | Run Dask jobs on your Flyte cluster |
+
+## Subpages
+- [Connectors](connectors.md)
+- [Flyte plugins](flyte-plugins/index.md)
+
+---
+**PAGE: API Reference**
+**SOURCE: api-reference/index.md**
+
+
+# Reference
+
+This section provides the reference material for the Flyte SDK and CLI.
+
+To get started, add `flyte` to your project
+
+```shell
+$ uv pip install --no-cache --prerelease=allow --upgrade flyte
+```
+
+This will install both the Flyte SDK and CLI.
+
+### ðŸ”— [Flyte SDK](flyte-sdk/index.md)
+
+The Flyte SDK provides the core Python API for building workflows and apps on your Union instance.
+
+### ðŸ”— [Flyte CLI](flyte-cli.md)
+
+The Flyte CLI is the command-line interface for interacting with your Union instance.
+
+## Subpages
+- [Flyte LLM context](flyte-context.md)
+- [Flyte CLI](flyte-cli.md)
+- [Flyte SDK](flyte-sdk/index.md)
+
+---
+**PAGE: API Reference**
+**SOURCE: api-reference/index.md**
+
+
+# Reference
+
+This section provides the reference material for the Flyte SDK and CLI.
+
+To get started, add `flyte` to your project
+
+```shell
+$ uv pip install --no-cache --prerelease=allow --upgrade flyte
+```
+
+This will install both the Flyte SDK and CLI.
+
+### ðŸ”— [Flyte SDK](flyte-sdk/index.md)
+
+The Flyte SDK provides the core Python API for building workflows and apps on your Union instance.
+
+### ðŸ”— [Flyte CLI](flyte-cli.md)
+
+The Flyte CLI is the command-line interface for interacting with your Union instance.
+
+## Subpages
+- [Flyte LLM context](flyte-context.md)
+- [Flyte CLI](flyte-cli.md)
+- [Flyte SDK](flyte-sdk/index.md)
+
+---
+**PAGE: Community**
+**SOURCE: community/index.md**
+
+
+# Community
+
+Union.ai is a commercial product built on top of the open source Flyte project.
+
+Since the success of Flyte is essential to the success of Union.ai,
+the company is dedicated to building and expanding the Flyte open source project and community.
+
+For information on how to get involved and how to keep in touch, see the [Flyte variant of this page](/docs/v2/flyte//community).
+
+## Contributing to documentation
+
+Union AI maintains and hosts both Flyte and Union documentation at [www.union.ai/docs](/docs/v2/root/).
+The two sets of documentation are deeply integrated, as the Union product is built on top of Flyte.
+To better maintain both sets of docs, they are hosted in the same repository (but rendered so that you can choose to view one or the other).
+
+Both the Flyte and Union documentation are open source.
+Flyte community members and Union customers are both welcome to contribute to the documentation.
+
+If you are interested, see [Contributing documentation and examples](./contributing-docs/_index).
+
+## Subpages
+- [Contributing docs and examples](contributing-docs/index.md)
+
+---
+**PAGE: Community**
+**SOURCE: community/index.md**
+
+
+# Community
+
+Union.ai is a commercial product built on top of the open source Flyte project.
+
+Since the success of Flyte is essential to the success of Union.ai,
+the company is dedicated to building and expanding the Flyte open source project and community.
+
+For information on how to get involved and how to keep in touch, see the [Flyte variant of this page](/docs/v2/flyte//community).
+
+## Contributing to documentation
+
+Union AI maintains and hosts both Flyte and Union documentation at [www.union.ai/docs](/docs/v2/root/).
+The two sets of documentation are deeply integrated, as the Union product is built on top of Flyte.
+To better maintain both sets of docs, they are hosted in the same repository (but rendered so that you can choose to view one or the other).
+
+Both the Flyte and Union documentation are open source.
+Flyte community members and Union customers are both welcome to contribute to the documentation.
+
+If you are interested, see [Contributing documentation and examples](./contributing-docs/_index).
+
+## Subpages
+- [Contributing docs and examples](contributing-docs/index.md)
+
+---
+**PAGE: Release Notes**
+**SOURCE: release-notes.md**
+
+
+# Release Notes
+
+## November 2025
+
+### :fast_forward: Grouped Runs
+We redesigned the Runs page to better support large numbers of runs. Historically, large projects produced so many runs that flat listings became difficult to navigate. The new design groups Runs by their root task - leveraging the fact that while there may be millions of runs, there are typically only dozens or hundreds of deployed tasks. This grouped view, combined with enhanced filtering (by status, owner, duration, and more coming soon), makes it dramatically faster and easier to locate the exact runs users are looking for, even in the largest deployments.
+
+![Grouped Runs View](https://raw.githubusercontent.com/unionai/unionai-docs-static/main/images/release-notes/2025-11_grouped_runs.gif)
+
+### :globe_with_meridians: Apps (beta)
+
+You can now deploy apps in Union 2.0. Apps let you host ML models, Streamlit dashboards, FastAPI services, and other interactive applications alongside your workflows. Simply define your app, deploy it, and Union will handle the infrastructure, routing, and lifecycle management. You can even call apps from your tasks to build end-to-end workflows that combine batch processing with real-time serving.
+
+To create an app, import `flyte` and use either `FastAPIAppEnvironment` for FastAPI applications or the generic `AppEnvironment` for other frameworks. Here's a simple FastAPI example:
+
+```python
+from fastapi import FastAPI
+import flyte
+from flyte.app.extras import FastAPIAppEnvironment
+
+app = FastAPI()
+env = FastAPIAppEnvironment(
+    name="my-api",
+    app=app,
+    image=flyte.Image.from_debian_base(python_version=(3, 12))
+        .with_pip_packages("fastapi", "uvicorn"),
+    resources=flyte.Resources(cpu=1, memory="512Mi"),
+    requires_auth=False,
+)
+
+@env.app.get("/greeting/{name}")
+async def greeting(name: str) -> str:
+    return f"Hello, {name}!"
+
+if __name__ == "__main__":
+    flyte.init_from_config()
+    flyte.deploy(env) # Deploy and serve your app
+```
+
+For Streamlit apps, use the generic `AppEnvironment` with a command:
+
+```python
+app_env = flyte.app.AppEnvironment(
+    name="streamlit-hello-v2",
+    image=flyte.Image.from_debian_base(python_version=(3, 12)).with_pip_packages("streamlit==1.41.1"),
+    command="streamlit hello --server.port 8080",
+    resources=flyte.Resources(cpu="1", memory="1Gi"),
+)
+```
+
+You can call apps from tasks by using `depends_on` and making HTTP requests to the app's endpoint. Please refer to the example in the [SDK repo](https://github.com/flyteorg/flyte-sdk/blob/main/examples/apps/call_apps_in_tasks/app.py). Similarly, you can call apps from other apps (see this [example](https://github.com/flyteorg/flyte-sdk/blob/main/examples/apps/app_calling_app/app.py)).
+
+### :label: Custom context
+
+You can now pass configuration and metadata implicitly through your entire task execution hierarchy using custom context. This is ideal for cross-cutting concerns like tracing IDs, experiment metadata, environment information, or logging correlation keysâ€”data that needs to be available everywhere but isn't logically part of your task's computation. 
+
+Custom context is a string key-value map that automatically flows from parent to child tasks without adding parameters to every function signature. Set it once at the run level with `with_runcontext()`, or override values within tasks using the `flyte.custom_context()` context manager:
+
+```python
+import flyte
+
+env = flyte.TaskEnvironment("custom-context-example")
+
+@env.task
+async def leaf_task() -> str:
+    # Reads run-level context
+    print("leaf sees:", flyte.ctx().custom_context)
+    return flyte.ctx().custom_context.get("trace_id")
+
+@env.task
+async def root() -> str:
+    return await leaf_task()
+
+if __name__ == "__main__":
+    flyte.init_from_config()
+    # Base context for the entire run
+    run = flyte.with_runcontext(custom_context={"trace_id": "root-abc", "experiment": "v1"}).run(root)
+    print(run.url)
+```
+
+### :lock: Secrets UI
+
+Now you can view and create secrets directly from the UI. Secrets are stored securely in your configured secrets manager and injected into your task environments at runtime.
+
+![Secrets Creation Flow](https://raw.githubusercontent.com/unionai/unionai-docs-static/main/images/release-notes/2025-11_secrets_creation.gif)
+
+### Image Builds now run in the same project-domain
+The image build task is now executed within the same project and domain as the user task, rather than in system-production. This change improves isolation and is a key step toward supporting multi-dataplane clusters.
+
+### Support for secret mounts in Poetry and UV projects
+We added support for mounting secrets into both Poetry and UV-based projects. This enables secure access to private dependencies or credentials during image build.
+
+```python
+import pathlib
+
+import flyte
+
+env = flyte.TaskEnvironment(
+    name="uv_project_lib",
+    resources=flyte.Resources(memory="1000Mi"),
+    image=(
+        flyte.Image.from_debian_base().with_uv_project(
+            pyproject_file=pathlib.Path(__file__).parent / "pyproject.toml",
+            pre=True,
+            secret_mounts="my_secret",
+        )
+    ),
+)
+```
+
+## October 2025
+
+### :infinity: Larger fanouts
+You can now run up to 50,000 actions within a run and up to 1,000 actions concurrently. 
+To enable observability across so many actions, we added group and sub-actions UI views, which show summary statistics about the actions which were spawned within a group or action.
+You can use these summary views (as well as the action status filter) to spot check long-running or failed actions.
+
+![50k Fanout Visualization](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_50k_fanout.gif)
+
+### :computer: Remote debugging for Ray head nodes
+Rather than locally reproducing errors, sometimes you just want to zoom into the remote execution and see what's happening.
+We directly enable this with the debug button.
+When you click "Debug action" from an action in a run, we spin up that action's environment, code, and input data, and attach a live VS Code debugger.
+Previously, this was only possible with vanilla Python tasks.
+Now, you can debug multi-node distributed computations on Ray directly.
+
+![Debugging Ray Head Node](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_ray_head_debug.gif)
+
+### :zap: Triggers and audit history
+[Triggers](../user-guide/task-configuration/triggers.md) let you templatize and set schedules for your workflows, similar to Launch Plans in Flyte 1.0.
+
+```python
+@env.task(triggers=flyte.Trigger.hourly())  # Every hour
+def example_task(trigger_time: datetime, x: int = 1) -> str:
+    return f"Task executed at {trigger_time.isoformat()} with x={x}"
+```
+
+Once you deploy, it's possible to see all the triggers which are associated with a task:
+
+![Triggers for a Task](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_triggers_for_task.png)
+
+We also maintain an audit history of every deploy, activation, and deactivation event, so you can get a sense of who's touched an automation.
+
+![Triggers Activity Log](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_trigger_activity_log.gif)
+
+### :arrow_up: Deployed tasks and input passing
+
+You can see the runs, task spec, and triggers associated with any deployed task, and launch it from the UI. We've converted the launch forms to a convenient JSON Schema syntax, so you can easily copy-paste the inputs from a previous run into a new run for any task.
+
+![Deployed Tasks and Input Passing](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_tasks_and_input_passing.gif)
diff --git a/consolidated_flyte_docs.md b/consolidated_flyte_docs.md
new file mode 100644
index 00000000..10c8bba4
--- /dev/null
+++ b/consolidated_flyte_docs.md
@@ -0,0 +1,355 @@
+# Documentation
+**Variant:** flyte  
+**Generated:** 2025-12-05
+
+This is a consolidated view of all documentation pages in hierarchical order.
+
+# Documentation
+
+Welcome to the documentation.
+
+## Subpages
+
+- [User Guide](user-guide/index.md)
+- [Tutorials](tutorials/index.md)
+- [Integrations](integrations/index.md)
+- [API Reference](api-reference/index.md)
+- [Community](community/index.md)
+- [Release Notes](release-notes.md)
+
+---
+**PAGE: User Guide**
+**SOURCE: user-guide/index.md**
+
+
+# Flyte
+
+Flyte is a free and open source platform that provides a full suite of powerful features for orchestrating AI workflows.
+Flyte empowers AI development teams to rapidly ship high-quality code to production by offering optimized performance, unparalleled resource efficiency, and a delightful workflow authoring experience.
+You deploy and manage Flyte yourself, on your own cloud infrastructure.
+
+> [!NOTE]
+> These are the Flyte **2.0 beta** docs.
+> To switch to [version 1.0](/docs/v1/flyte/) or to the commercial product, [**Union.ai**](/docs/v2/byoc/), use the selectors above.
+>
+> This documentation for open-source Flyte is maintained by Union.ai.
+
+### ðŸ’¡ [Flyte 2](flyte-2/index.md)
+
+Flyte 2 represents a fundamental shift in how AI workflows are written and executed. Learn
+more in this section.
+
+### ðŸ”¢ [Getting started](getting-started/index.md)
+
+Install Flyte 2, configure your local IDE, create and run your first task, and inspect the results in 2 minutes.
+
+## Subpages
+- [Flyte 2](flyte-2/index.md)
+- [Getting started](getting-started/index.md)
+- [Task configuration](task-configuration/index.md)
+- [Task programming](task-programming/index.md)
+- [Considerations](considerations.md)
+
+---
+**PAGE: User Guide**
+**SOURCE: user-guide/index.md**
+
+
+# Flyte
+
+Flyte is a free and open source platform that provides a full suite of powerful features for orchestrating AI workflows.
+Flyte empowers AI development teams to rapidly ship high-quality code to production by offering optimized performance, unparalleled resource efficiency, and a delightful workflow authoring experience.
+You deploy and manage Flyte yourself, on your own cloud infrastructure.
+
+> [!NOTE]
+> These are the Flyte **2.0 beta** docs.
+> To switch to [version 1.0](/docs/v1/flyte/) or to the commercial product, [**Union.ai**](/docs/v2/byoc/), use the selectors above.
+>
+> This documentation for open-source Flyte is maintained by Union.ai.
+
+### ðŸ’¡ [Flyte 2](flyte-2/index.md)
+
+Flyte 2 represents a fundamental shift in how AI workflows are written and executed. Learn
+more in this section.
+
+### ðŸ”¢ [Getting started](getting-started/index.md)
+
+Install Flyte 2, configure your local IDE, create and run your first task, and inspect the results in 2 minutes.
+
+## Subpages
+- [Flyte 2](flyte-2/index.md)
+- [Getting started](getting-started/index.md)
+- [Task configuration](task-configuration/index.md)
+- [Task programming](task-programming/index.md)
+- [Considerations](considerations.md)
+
+---
+**PAGE: Tutorials**
+**SOURCE: tutorials/index.md**
+
+
+# Tutorials
+
+This section contains tutorials that showcase relevant use cases and provide step-by-step instructions on how to implement various features using Flyte and Union.
+
+### ðŸ”— [Multi-agent trading simulation](trading-agents.md)
+
+A multi-agent trading simulation, modeling how agents within a firm might interact, strategize, and make trades collaboratively.
+
+### ðŸ”— [Run LLM-generated code](code-agent.md)
+
+Securely execute and iterate on LLM-generated code using a code agent with error reflection and retry logic.
+
+### ðŸ”— [Deep research](deep-research.md)
+
+Build an agentic workflow for deep research with multi-step reasoning and evaluation.
+
+### ðŸ”— [Hyperparameter optimization](hpo.md)
+
+Run large-scale HPO experiments with zero manual tracking, deterministic results, and automatic recovery.
+
+### ðŸ”— [Automatic prompt engineering](auto_prompt_engineering.md)
+
+Easily run prompt optimization with real-time observability, traceability, and automatic recovery.
+
+### ðŸ”— [Text-to-SQL](text_to_sql.md)
+
+Learn how to turn natural language questions into SQL queries with Flyte and LlamaIndex, and explore prompt optimization in practice.
+
+## Subpages
+- [Automatic prompt engineering](auto_prompt_engineering.md)
+- [Deep research](deep-research.md)
+- [Hyperparameter optimization](hpo.md)
+- [Multi-agent trading simulation](trading-agents.md)
+- [Run LLM-generated code](code-agent.md)
+- [Text-to-SQL](text_to_sql.md)
+
+---
+**PAGE: Tutorials**
+**SOURCE: tutorials/index.md**
+
+
+# Tutorials
+
+This section contains tutorials that showcase relevant use cases and provide step-by-step instructions on how to implement various features using Flyte and Union.
+
+### ðŸ”— [Multi-agent trading simulation](trading-agents.md)
+
+A multi-agent trading simulation, modeling how agents within a firm might interact, strategize, and make trades collaboratively.
+
+### ðŸ”— [Run LLM-generated code](code-agent.md)
+
+Securely execute and iterate on LLM-generated code using a code agent with error reflection and retry logic.
+
+### ðŸ”— [Deep research](deep-research.md)
+
+Build an agentic workflow for deep research with multi-step reasoning and evaluation.
+
+### ðŸ”— [Hyperparameter optimization](hpo.md)
+
+Run large-scale HPO experiments with zero manual tracking, deterministic results, and automatic recovery.
+
+### ðŸ”— [Automatic prompt engineering](auto_prompt_engineering.md)
+
+Easily run prompt optimization with real-time observability, traceability, and automatic recovery.
+
+### ðŸ”— [Text-to-SQL](text_to_sql.md)
+
+Learn how to turn natural language questions into SQL queries with Flyte and LlamaIndex, and explore prompt optimization in practice.
+
+## Subpages
+- [Automatic prompt engineering](auto_prompt_engineering.md)
+- [Deep research](deep-research.md)
+- [Hyperparameter optimization](hpo.md)
+- [Multi-agent trading simulation](trading-agents.md)
+- [Run LLM-generated code](code-agent.md)
+- [Text-to-SQL](text_to_sql.md)
+
+---
+**PAGE: Integrations**
+**SOURCE: integrations/index.md**
+
+
+# Integrations
+
+Flyte is designed to be highly extensible and can be customized
+in multiple ways.
+
+## Flyte Plugins
+
+Flyte plugins extend the functionality of the `flyte` SDK.
+
+| Plugin | Description |
+| ------ | ----------- |
+| [Ray](flyte-plugins/ray.md) | Run Ray jobs on your Flyte cluster |
+| [Spark](flyte-plugins/spark.md) | Run Spark jobs on your Flyte cluster |
+| [OpenAI](flyte-plugins/openai/index.md) | Integrate with OpenAI SDKs in your Flyte workflows |
+| [Dask](flyte-plugins/dask.md) | Run Dask jobs on your Flyte cluster |
+
+## Subpages
+- [Connectors](connectors.md)
+- [Flyte plugins](flyte-plugins/index.md)
+
+---
+**PAGE: Integrations**
+**SOURCE: integrations/index.md**
+
+
+# Integrations
+
+Flyte is designed to be highly extensible and can be customized
+in multiple ways.
+
+## Flyte Plugins
+
+Flyte plugins extend the functionality of the `flyte` SDK.
+
+| Plugin | Description |
+| ------ | ----------- |
+| [Ray](flyte-plugins/ray.md) | Run Ray jobs on your Flyte cluster |
+| [Spark](flyte-plugins/spark.md) | Run Spark jobs on your Flyte cluster |
+| [OpenAI](flyte-plugins/openai/index.md) | Integrate with OpenAI SDKs in your Flyte workflows |
+| [Dask](flyte-plugins/dask.md) | Run Dask jobs on your Flyte cluster |
+
+## Subpages
+- [Connectors](connectors.md)
+- [Flyte plugins](flyte-plugins/index.md)
+
+---
+**PAGE: API Reference**
+**SOURCE: api-reference/index.md**
+
+
+# Reference
+
+This section provides the reference material for the Flyte SDK and CLI.
+
+To get started, add `flyte` to your project
+
+```shell
+$ uv pip install --no-cache --prerelease=allow --upgrade flyte
+```
+
+This will install both the Flyte SDK and CLI.
+
+### ðŸ”— [Flyte SDK](flyte-sdk/index.md)
+
+The Flyte SDK provides the core Python API for building workflows and apps on your Union instance.
+
+### ðŸ”— [Flyte CLI](flyte-cli.md)
+
+The Flyte CLI is the command-line interface for interacting with your Union instance.
+
+## Subpages
+- [Flyte LLM context](flyte-context.md)
+- [Flyte CLI](flyte-cli.md)
+- [Flyte SDK](flyte-sdk/index.md)
+
+---
+**PAGE: API Reference**
+**SOURCE: api-reference/index.md**
+
+
+# Reference
+
+This section provides the reference material for the Flyte SDK and CLI.
+
+To get started, add `flyte` to your project
+
+```shell
+$ uv pip install --no-cache --prerelease=allow --upgrade flyte
+```
+
+This will install both the Flyte SDK and CLI.
+
+### ðŸ”— [Flyte SDK](flyte-sdk/index.md)
+
+The Flyte SDK provides the core Python API for building workflows and apps on your Union instance.
+
+### ðŸ”— [Flyte CLI](flyte-cli.md)
+
+The Flyte CLI is the command-line interface for interacting with your Union instance.
+
+## Subpages
+- [Flyte LLM context](flyte-context.md)
+- [Flyte CLI](flyte-cli.md)
+- [Flyte SDK](flyte-sdk/index.md)
+
+---
+**PAGE: Community**
+**SOURCE: community/index.md**
+
+
+# Community
+
+Flyte is an open source project that is built and maintained by a community of contributors.
+Union AI is the primary maintainer of Flyte and developer of Union.ai, a closed source commercial product that is built on top of Flyte.
+
+Since the success of Flyte is essential to the success of Union.ai,
+the company is dedicated to building and expanding the Flyte open source project and community.
+
+For information on how to get involved and how to keep in touch, see [Joining the community](joining-the-community.md).
+
+## Contributing to the codebase
+
+The full Flyte codebase is open source and available on GitHub.
+If you are interested, see [Contributing code](contributing-code.md).
+
+## Contributing to documentation
+
+Union AI maintains and hosts both Flyte and Union documentation at [www.union.ai/docs](/docs/v2/root/).
+The two sets of documentation are deeply integrated, as the Union product is built on top of Flyte.
+To better maintain both sets of docs, they are hosted in the same repository (but rendered so that you can choose to view one or the other).
+
+Both the Flyte and Union documentation are open source.
+Flyte community members and Union customers are both welcome to contribute to the documentation.
+
+If you are interested, see [Contributing documentation and examples](./contributing-docs/_index).
+
+## Subpages
+- [Joining the community](joining-the-community.md)
+- [Contributing code](contributing-code.md)
+- [Contributing docs and examples](contributing-docs/index.md)
+
+---
+**PAGE: Community**
+**SOURCE: community/index.md**
+
+
+# Community
+
+Flyte is an open source project that is built and maintained by a community of contributors.
+Union AI is the primary maintainer of Flyte and developer of Union.ai, a closed source commercial product that is built on top of Flyte.
+
+Since the success of Flyte is essential to the success of Union.ai,
+the company is dedicated to building and expanding the Flyte open source project and community.
+
+For information on how to get involved and how to keep in touch, see [Joining the community](joining-the-community.md).
+
+## Contributing to the codebase
+
+The full Flyte codebase is open source and available on GitHub.
+If you are interested, see [Contributing code](contributing-code.md).
+
+## Contributing to documentation
+
+Union AI maintains and hosts both Flyte and Union documentation at [www.union.ai/docs](/docs/v2/root/).
+The two sets of documentation are deeply integrated, as the Union product is built on top of Flyte.
+To better maintain both sets of docs, they are hosted in the same repository (but rendered so that you can choose to view one or the other).
+
+Both the Flyte and Union documentation are open source.
+Flyte community members and Union customers are both welcome to contribute to the documentation.
+
+If you are interested, see [Contributing documentation and examples](./contributing-docs/_index).
+
+## Subpages
+- [Joining the community](joining-the-community.md)
+- [Contributing code](contributing-code.md)
+- [Contributing docs and examples](contributing-docs/index.md)
+
+---
+**PAGE: Release Notes**
+**SOURCE: release-notes.md**
+
+
+# Release Notes
diff --git a/consolidated_selfmanaged_docs.md b/consolidated_selfmanaged_docs.md
new file mode 100644
index 00000000..bf3dd9fd
--- /dev/null
+++ b/consolidated_selfmanaged_docs.md
@@ -0,0 +1,498 @@
+# Documentation
+**Variant:** selfmanaged  
+**Generated:** 2025-12-05
+
+This is a consolidated view of all documentation pages in hierarchical order.
+
+# Documentation
+
+Welcome to the documentation.
+
+## Subpages
+
+- [User Guide](user-guide/index.md)
+- [Tutorials](tutorials/index.md)
+- [Integrations](integrations/index.md)
+- [API Reference](api-reference/index.md)
+- [Community](community/index.md)
+- [Release Notes](release-notes.md)
+
+---
+**PAGE: User Guide**
+**SOURCE: user-guide/index.md**
+
+
+# Union.ai Self-managed
+
+Union.ai empowers AI development teams to rapidly ship high-quality code to production by offering optimized performance, unparalleled resource efficiency, and a delightful workflow authoring experience. With Union.ai your team can:
+
+* Run complex AI workloads with performance, scale, and efficiency.
+* Achieve millisecond-level execution times with reusable containers.
+* Scale out to multiple regions, clusters, and clouds as needed for resource availability, scale, or compliance.
+
+> [!NOTE]
+> These are the Union.ai **2.0 beta** docs.
+> To switch to [version 1.0](/docs/v1/selfmanaged/) or to another product variant, use the selectors above.
+>
+> Union.ai is built on top of the leading open-source workflow orchestrator, [Flyte](/docs/v2/flyte/).
+>
+> Union.ai Self-managed provides all the features of Flyte, plus much more
+> while letting you keep your data and workflow code on your infrastructure and under your own management.
+
+### ðŸ’¡ [Flyte 2](flyte-2/index.md)
+
+Flyte 2 represents a fundamental shift in how AI workflows are written and executed. Learn
+more in this section.
+
+### ðŸ”¢ [Getting started](getting-started/index.md)
+
+Install Flyte 2, configure your local IDE, create and run your first task, and inspect the results in 2 minutes.
+
+## Subpages
+- [Flyte 2](flyte-2/index.md)
+- [Getting started](getting-started/index.md)
+- [Task configuration](task-configuration/index.md)
+- [Task programming](task-programming/index.md)
+- [Considerations](considerations.md)
+
+---
+**PAGE: User Guide**
+**SOURCE: user-guide/index.md**
+
+
+# Union.ai Self-managed
+
+Union.ai empowers AI development teams to rapidly ship high-quality code to production by offering optimized performance, unparalleled resource efficiency, and a delightful workflow authoring experience. With Union.ai your team can:
+
+* Run complex AI workloads with performance, scale, and efficiency.
+* Achieve millisecond-level execution times with reusable containers.
+* Scale out to multiple regions, clusters, and clouds as needed for resource availability, scale, or compliance.
+
+> [!NOTE]
+> These are the Union.ai **2.0 beta** docs.
+> To switch to [version 1.0](/docs/v1/selfmanaged/) or to another product variant, use the selectors above.
+>
+> Union.ai is built on top of the leading open-source workflow orchestrator, [Flyte](/docs/v2/flyte/).
+>
+> Union.ai Self-managed provides all the features of Flyte, plus much more
+> while letting you keep your data and workflow code on your infrastructure and under your own management.
+
+### ðŸ’¡ [Flyte 2](flyte-2/index.md)
+
+Flyte 2 represents a fundamental shift in how AI workflows are written and executed. Learn
+more in this section.
+
+### ðŸ”¢ [Getting started](getting-started/index.md)
+
+Install Flyte 2, configure your local IDE, create and run your first task, and inspect the results in 2 minutes.
+
+## Subpages
+- [Flyte 2](flyte-2/index.md)
+- [Getting started](getting-started/index.md)
+- [Task configuration](task-configuration/index.md)
+- [Task programming](task-programming/index.md)
+- [Considerations](considerations.md)
+
+---
+**PAGE: Tutorials**
+**SOURCE: tutorials/index.md**
+
+
+# Tutorials
+
+This section contains tutorials that showcase relevant use cases and provide step-by-step instructions on how to implement various features using Flyte and Union.
+
+### ðŸ”— [Multi-agent trading simulation](trading-agents.md)
+
+A multi-agent trading simulation, modeling how agents within a firm might interact, strategize, and make trades collaboratively.
+
+### ðŸ”— [Run LLM-generated code](code-agent.md)
+
+Securely execute and iterate on LLM-generated code using a code agent with error reflection and retry logic.
+
+### ðŸ”— [Deep research](deep-research.md)
+
+Build an agentic workflow for deep research with multi-step reasoning and evaluation.
+
+### ðŸ”— [Hyperparameter optimization](hpo.md)
+
+Run large-scale HPO experiments with zero manual tracking, deterministic results, and automatic recovery.
+
+### ðŸ”— [Automatic prompt engineering](auto_prompt_engineering.md)
+
+Easily run prompt optimization with real-time observability, traceability, and automatic recovery.
+
+### ðŸ”— [Text-to-SQL](text_to_sql.md)
+
+Learn how to turn natural language questions into SQL queries with Flyte and LlamaIndex, and explore prompt optimization in practice.
+
+## Subpages
+- [Automatic prompt engineering](auto_prompt_engineering.md)
+- [Deep research](deep-research.md)
+- [Hyperparameter optimization](hpo.md)
+- [Multi-agent trading simulation](trading-agents.md)
+- [Run LLM-generated code](code-agent.md)
+- [Text-to-SQL](text_to_sql.md)
+
+---
+**PAGE: Tutorials**
+**SOURCE: tutorials/index.md**
+
+
+# Tutorials
+
+This section contains tutorials that showcase relevant use cases and provide step-by-step instructions on how to implement various features using Flyte and Union.
+
+### ðŸ”— [Multi-agent trading simulation](trading-agents.md)
+
+A multi-agent trading simulation, modeling how agents within a firm might interact, strategize, and make trades collaboratively.
+
+### ðŸ”— [Run LLM-generated code](code-agent.md)
+
+Securely execute and iterate on LLM-generated code using a code agent with error reflection and retry logic.
+
+### ðŸ”— [Deep research](deep-research.md)
+
+Build an agentic workflow for deep research with multi-step reasoning and evaluation.
+
+### ðŸ”— [Hyperparameter optimization](hpo.md)
+
+Run large-scale HPO experiments with zero manual tracking, deterministic results, and automatic recovery.
+
+### ðŸ”— [Automatic prompt engineering](auto_prompt_engineering.md)
+
+Easily run prompt optimization with real-time observability, traceability, and automatic recovery.
+
+### ðŸ”— [Text-to-SQL](text_to_sql.md)
+
+Learn how to turn natural language questions into SQL queries with Flyte and LlamaIndex, and explore prompt optimization in practice.
+
+## Subpages
+- [Automatic prompt engineering](auto_prompt_engineering.md)
+- [Deep research](deep-research.md)
+- [Hyperparameter optimization](hpo.md)
+- [Multi-agent trading simulation](trading-agents.md)
+- [Run LLM-generated code](code-agent.md)
+- [Text-to-SQL](text_to_sql.md)
+
+---
+**PAGE: Integrations**
+**SOURCE: integrations/index.md**
+
+
+# Integrations
+
+Flyte is designed to be highly extensible and can be customized
+in multiple ways.
+
+## Flyte Plugins
+
+Flyte plugins extend the functionality of the `flyte` SDK.
+
+| Plugin | Description |
+| ------ | ----------- |
+| [Ray](flyte-plugins/ray.md) | Run Ray jobs on your Flyte cluster |
+| [Spark](flyte-plugins/spark.md) | Run Spark jobs on your Flyte cluster |
+| [OpenAI](flyte-plugins/openai/index.md) | Integrate with OpenAI SDKs in your Flyte workflows |
+| [Dask](flyte-plugins/dask.md) | Run Dask jobs on your Flyte cluster |
+
+## Subpages
+- [Connectors](connectors.md)
+- [Flyte plugins](flyte-plugins/index.md)
+
+---
+**PAGE: Integrations**
+**SOURCE: integrations/index.md**
+
+
+# Integrations
+
+Flyte is designed to be highly extensible and can be customized
+in multiple ways.
+
+## Flyte Plugins
+
+Flyte plugins extend the functionality of the `flyte` SDK.
+
+| Plugin | Description |
+| ------ | ----------- |
+| [Ray](flyte-plugins/ray.md) | Run Ray jobs on your Flyte cluster |
+| [Spark](flyte-plugins/spark.md) | Run Spark jobs on your Flyte cluster |
+| [OpenAI](flyte-plugins/openai/index.md) | Integrate with OpenAI SDKs in your Flyte workflows |
+| [Dask](flyte-plugins/dask.md) | Run Dask jobs on your Flyte cluster |
+
+## Subpages
+- [Connectors](connectors.md)
+- [Flyte plugins](flyte-plugins/index.md)
+
+---
+**PAGE: API Reference**
+**SOURCE: api-reference/index.md**
+
+
+# Reference
+
+This section provides the reference material for the Flyte SDK and CLI.
+
+To get started, add `flyte` to your project
+
+```shell
+$ uv pip install --no-cache --prerelease=allow --upgrade flyte
+```
+
+This will install both the Flyte SDK and CLI.
+
+### ðŸ”— [Flyte SDK](flyte-sdk/index.md)
+
+The Flyte SDK provides the core Python API for building workflows and apps on your Union instance.
+
+### ðŸ”— [Flyte CLI](flyte-cli.md)
+
+The Flyte CLI is the command-line interface for interacting with your Union instance.
+
+## Subpages
+- [Flyte LLM context](flyte-context.md)
+- [Flyte CLI](flyte-cli.md)
+- [Flyte SDK](flyte-sdk/index.md)
+
+---
+**PAGE: API Reference**
+**SOURCE: api-reference/index.md**
+
+
+# Reference
+
+This section provides the reference material for the Flyte SDK and CLI.
+
+To get started, add `flyte` to your project
+
+```shell
+$ uv pip install --no-cache --prerelease=allow --upgrade flyte
+```
+
+This will install both the Flyte SDK and CLI.
+
+### ðŸ”— [Flyte SDK](flyte-sdk/index.md)
+
+The Flyte SDK provides the core Python API for building workflows and apps on your Union instance.
+
+### ðŸ”— [Flyte CLI](flyte-cli.md)
+
+The Flyte CLI is the command-line interface for interacting with your Union instance.
+
+## Subpages
+- [Flyte LLM context](flyte-context.md)
+- [Flyte CLI](flyte-cli.md)
+- [Flyte SDK](flyte-sdk/index.md)
+
+---
+**PAGE: Community**
+**SOURCE: community/index.md**
+
+
+# Community
+
+Union.ai is a commercial product built on top of the open source Flyte project.
+
+Since the success of Flyte is essential to the success of Union.ai,
+the company is dedicated to building and expanding the Flyte open source project and community.
+
+For information on how to get involved and how to keep in touch, see the [Flyte variant of this page](/docs/v2/flyte//community).
+
+## Contributing to documentation
+
+Union AI maintains and hosts both Flyte and Union documentation at [www.union.ai/docs](/docs/v2/root/).
+The two sets of documentation are deeply integrated, as the Union product is built on top of Flyte.
+To better maintain both sets of docs, they are hosted in the same repository (but rendered so that you can choose to view one or the other).
+
+Both the Flyte and Union documentation are open source.
+Flyte community members and Union customers are both welcome to contribute to the documentation.
+
+If you are interested, see [Contributing documentation and examples](./contributing-docs/_index).
+
+## Subpages
+- [Contributing docs and examples](contributing-docs/index.md)
+
+---
+**PAGE: Community**
+**SOURCE: community/index.md**
+
+
+# Community
+
+Union.ai is a commercial product built on top of the open source Flyte project.
+
+Since the success of Flyte is essential to the success of Union.ai,
+the company is dedicated to building and expanding the Flyte open source project and community.
+
+For information on how to get involved and how to keep in touch, see the [Flyte variant of this page](/docs/v2/flyte//community).
+
+## Contributing to documentation
+
+Union AI maintains and hosts both Flyte and Union documentation at [www.union.ai/docs](/docs/v2/root/).
+The two sets of documentation are deeply integrated, as the Union product is built on top of Flyte.
+To better maintain both sets of docs, they are hosted in the same repository (but rendered so that you can choose to view one or the other).
+
+Both the Flyte and Union documentation are open source.
+Flyte community members and Union customers are both welcome to contribute to the documentation.
+
+If you are interested, see [Contributing documentation and examples](./contributing-docs/_index).
+
+## Subpages
+- [Contributing docs and examples](contributing-docs/index.md)
+
+---
+**PAGE: Release Notes**
+**SOURCE: release-notes.md**
+
+
+# Release Notes
+
+## November 2025
+
+### :fast_forward: Grouped Runs
+We redesigned the Runs page to better support large numbers of runs. Historically, large projects produced so many runs that flat listings became difficult to navigate. The new design groups Runs by their root task - leveraging the fact that while there may be millions of runs, there are typically only dozens or hundreds of deployed tasks. This grouped view, combined with enhanced filtering (by status, owner, duration, and more coming soon), makes it dramatically faster and easier to locate the exact runs users are looking for, even in the largest deployments.
+
+![Grouped Runs View](https://raw.githubusercontent.com/unionai/unionai-docs-static/main/images/release-notes/2025-11_grouped_runs.gif)
+
+### :globe_with_meridians: Apps (beta)
+
+You can now deploy apps in Union 2.0. Apps let you host ML models, Streamlit dashboards, FastAPI services, and other interactive applications alongside your workflows. Simply define your app, deploy it, and Union will handle the infrastructure, routing, and lifecycle management. You can even call apps from your tasks to build end-to-end workflows that combine batch processing with real-time serving.
+
+To create an app, import `flyte` and use either `FastAPIAppEnvironment` for FastAPI applications or the generic `AppEnvironment` for other frameworks. Here's a simple FastAPI example:
+
+```python
+from fastapi import FastAPI
+import flyte
+from flyte.app.extras import FastAPIAppEnvironment
+
+app = FastAPI()
+env = FastAPIAppEnvironment(
+    name="my-api",
+    app=app,
+    image=flyte.Image.from_debian_base(python_version=(3, 12))
+        .with_pip_packages("fastapi", "uvicorn"),
+    resources=flyte.Resources(cpu=1, memory="512Mi"),
+    requires_auth=False,
+)
+
+@env.app.get("/greeting/{name}")
+async def greeting(name: str) -> str:
+    return f"Hello, {name}!"
+
+if __name__ == "__main__":
+    flyte.init_from_config()
+    flyte.deploy(env) # Deploy and serve your app
+```
+
+For Streamlit apps, use the generic `AppEnvironment` with a command:
+
+```python
+app_env = flyte.app.AppEnvironment(
+    name="streamlit-hello-v2",
+    image=flyte.Image.from_debian_base(python_version=(3, 12)).with_pip_packages("streamlit==1.41.1"),
+    command="streamlit hello --server.port 8080",
+    resources=flyte.Resources(cpu="1", memory="1Gi"),
+)
+```
+
+You can call apps from tasks by using `depends_on` and making HTTP requests to the app's endpoint. Please refer to the example in the [SDK repo](https://github.com/flyteorg/flyte-sdk/blob/main/examples/apps/call_apps_in_tasks/app.py). Similarly, you can call apps from other apps (see this [example](https://github.com/flyteorg/flyte-sdk/blob/main/examples/apps/app_calling_app/app.py)).
+
+### :label: Custom context
+
+You can now pass configuration and metadata implicitly through your entire task execution hierarchy using custom context. This is ideal for cross-cutting concerns like tracing IDs, experiment metadata, environment information, or logging correlation keysâ€”data that needs to be available everywhere but isn't logically part of your task's computation. 
+
+Custom context is a string key-value map that automatically flows from parent to child tasks without adding parameters to every function signature. Set it once at the run level with `with_runcontext()`, or override values within tasks using the `flyte.custom_context()` context manager:
+
+```python
+import flyte
+
+env = flyte.TaskEnvironment("custom-context-example")
+
+@env.task
+async def leaf_task() -> str:
+    # Reads run-level context
+    print("leaf sees:", flyte.ctx().custom_context)
+    return flyte.ctx().custom_context.get("trace_id")
+
+@env.task
+async def root() -> str:
+    return await leaf_task()
+
+if __name__ == "__main__":
+    flyte.init_from_config()
+    # Base context for the entire run
+    run = flyte.with_runcontext(custom_context={"trace_id": "root-abc", "experiment": "v1"}).run(root)
+    print(run.url)
+```
+
+### :lock: Secrets UI
+
+Now you can view and create secrets directly from the UI. Secrets are stored securely in your configured secrets manager and injected into your task environments at runtime.
+
+![Secrets Creation Flow](https://raw.githubusercontent.com/unionai/unionai-docs-static/main/images/release-notes/2025-11_secrets_creation.gif)
+
+### Image Builds now run in the same project-domain
+The image build task is now executed within the same project and domain as the user task, rather than in system-production. This change improves isolation and is a key step toward supporting multi-dataplane clusters.
+
+### Support for secret mounts in Poetry and UV projects
+We added support for mounting secrets into both Poetry and UV-based projects. This enables secure access to private dependencies or credentials during image build.
+
+```python
+import pathlib
+
+import flyte
+
+env = flyte.TaskEnvironment(
+    name="uv_project_lib",
+    resources=flyte.Resources(memory="1000Mi"),
+    image=(
+        flyte.Image.from_debian_base().with_uv_project(
+            pyproject_file=pathlib.Path(__file__).parent / "pyproject.toml",
+            pre=True,
+            secret_mounts="my_secret",
+        )
+    ),
+)
+```
+
+## October 2025
+
+### :infinity: Larger fanouts
+You can now run up to 50,000 actions within a run and up to 1,000 actions concurrently. 
+To enable observability across so many actions, we added group and sub-actions UI views, which show summary statistics about the actions which were spawned within a group or action.
+You can use these summary views (as well as the action status filter) to spot check long-running or failed actions.
+
+![50k Fanout Visualization](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_50k_fanout.gif)
+
+### :computer: Remote debugging for Ray head nodes
+Rather than locally reproducing errors, sometimes you just want to zoom into the remote execution and see what's happening.
+We directly enable this with the debug button.
+When you click "Debug action" from an action in a run, we spin up that action's environment, code, and input data, and attach a live VS Code debugger.
+Previously, this was only possible with vanilla Python tasks.
+Now, you can debug multi-node distributed computations on Ray directly.
+
+![Debugging Ray Head Node](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_ray_head_debug.gif)
+
+### :zap: Triggers and audit history
+[Triggers](../user-guide/task-configuration/triggers.md) let you templatize and set schedules for your workflows, similar to Launch Plans in Flyte 1.0.
+
+```python
+@env.task(triggers=flyte.Trigger.hourly())  # Every hour
+def example_task(trigger_time: datetime, x: int = 1) -> str:
+    return f"Task executed at {trigger_time.isoformat()} with x={x}"
+```
+
+Once you deploy, it's possible to see all the triggers which are associated with a task:
+
+![Triggers for a Task](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_triggers_for_task.png)
+
+We also maintain an audit history of every deploy, activation, and deactivation event, so you can get a sense of who's touched an automation.
+
+![Triggers Activity Log](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_trigger_activity_log.gif)
+
+### :arrow_up: Deployed tasks and input passing
+
+You can see the runs, task spec, and triggers associated with any deployed task, and launch it from the UI. We've converted the launch forms to a convenient JSON Schema syntax, so you can easily copy-paste the inputs from a previous run into a new run for any task.
+
+![Deployed Tasks and Input Passing](https://raw.githubusercontent.com/unionai/unionai-docs-static/refs/heads/main/images/release-notes/2025-10_tasks_and_input_passing.gif)
diff --git a/content/404.md b/content/404.md
index 8bfa26b6..2e37495c 100644
--- a/content/404.md
+++ b/content/404.md
@@ -1,7 +1,6 @@
 ---
 title: 404 - Not Found
 variants: +flyte +serverless +byoc +selfmanaged
-layout: four-o-four
 toc_enabled: false
 sidebar_enabled: false
 ---
diff --git a/hugo.toml b/hugo.toml
index ffb62f42..52031f24 100644
--- a/hugo.toml
+++ b/hugo.toml
@@ -6,7 +6,6 @@
 # For variant-specific settings, use config.<variant>.toml.
 
 languageCode = 'en-us'
-theme = 'union'
 disableKinds = ["RSS"]
 enableRobotsTXT = true
 enableEmoji = true
@@ -16,11 +15,11 @@ enableEmoji = true
   # 'home': The main site homepage. 'HTML' for the page, 'RSS' for feed readers.
   home = ["HTML", "RSS"]
 
-  # 'page': Individual content pages. Only 'HTML' is needed for standard page rendering.
-  page = ["HTML"]
+  # 'page': Individual content pages. 'HTML' for the page, 'MD' for markdown processing.
+  page = ["HTML", "MD"]
 
-  # 'section': Top-level content sections (e.g., docs, tutorials). 'HTML' for rendering, 'RSS' for section-specific feeds.
-  section = ["HTML", "RSS"]
+  # 'section': Top-level content sections (e.g., docs, tutorials). 'HTML' for rendering, 'RSS' for section-specific feeds, 'MD' for markdown processing.
+  section = ["HTML", "RSS", "MD"]
 
   # 'taxonomy': Used for tag/category listing pages. 'HTML' for rendering, 'RSS' for taxonomy feeds.
   taxonomy = ["HTML", "RSS"]
@@ -28,6 +27,13 @@ enableEmoji = true
   # 'robotsTXT': Generate robots.txt file for search engine crawling
   robotsTXT = ["ROBOTS"]
 
+[outputFormats]
+  [outputFormats.MD]
+    mediaType = "text/plain"
+    baseName = "index"
+    path = "tmp-md"
+    isPlainText = true
+
 [params]
 _merge = "deep"
 show_inactive = false
diff --git a/themes/union/layouts/_default/baseof.html b/layouts/_default/baseof.html
similarity index 100%
rename from themes/union/layouts/_default/baseof.html
rename to layouts/_default/baseof.html
diff --git a/layouts/_default/baseof.md b/layouts/_default/baseof.md
new file mode 100644
index 00000000..3dd7f7da
--- /dev/null
+++ b/layouts/_default/baseof.md
@@ -0,0 +1,2 @@
+{{- /* Base template for markdown output format */ -}}
+{{ block "main" . }}{{ end }}
\ No newline at end of file
diff --git a/themes/union/layouts/_default/four-o-four.html b/layouts/_default/four-o-four.html
similarity index 100%
rename from themes/union/layouts/_default/four-o-four.html
rename to layouts/_default/four-o-four.html
diff --git a/themes/union/layouts/_default/list.html b/layouts/_default/list.html
similarity index 100%
rename from themes/union/layouts/_default/list.html
rename to layouts/_default/list.html
diff --git a/layouts/_default/list.md b/layouts/_default/list.md
new file mode 100644
index 00000000..0c0e512c
--- /dev/null
+++ b/layouts/_default/list.md
@@ -0,0 +1,40 @@
+{{ define "main" }}
+{{- /*
+Template for generating markdown versions of section/list pages.
+This renders section content and lists child pages in markdown format.
+*/ -}}
+{{- if .Params.description }}
+
+{{ .Params.description }}
+{{- end }}
+
+{{ .RawContent }}
+
+{{- if .Pages }}
+
+## Subpages
+
+{{- $sortedPages := .Pages.ByWeight }}
+{{- range $sortedPages }}
+{{- if (partial "page-allowed.html" .).allowed }}
+{{- $section := "" }}
+{{- if eq .Kind "section" }}
+{{- /* For section pages (directories), get the directory name from File.Dir */}}
+{{- $section = strings.TrimSuffix "/" .File.Dir }}
+{{- $section = path.Base $section }}
+{{- else }}
+{{- /* For regular pages (files), use the file's base name */}}
+{{- $section = .File.BaseFileName }}
+{{- end }}
+- [{{ .Title }}]({{ $section }}/) {{- if .Params.description }} - {{ .Params.description }}{{ end }}
+{{- end }}
+{{- end }}
+{{- end }}
+
+---
+**Source**: {{ .File.Path }}
+**URL**: {{ .Permalink }}
+{{- if .Date }}
+**Date**: {{ .Date.Format "2006-01-02" }}
+{{- end }}
+{{ end }}
\ No newline at end of file
diff --git a/themes/union/layouts/_default/plugin.html b/layouts/_default/plugin.html
similarity index 100%
rename from themes/union/layouts/_default/plugin.html
rename to layouts/_default/plugin.html
diff --git a/themes/union/layouts/_default/py_api.html b/layouts/_default/py_api.html
similarity index 100%
rename from themes/union/layouts/_default/py_api.html
rename to layouts/_default/py_api.html
diff --git a/themes/union/layouts/_default/py_example.html b/layouts/_default/py_example.html
similarity index 100%
rename from themes/union/layouts/_default/py_example.html
rename to layouts/_default/py_example.html
diff --git a/themes/union/layouts/_default/single.html b/layouts/_default/single.html
similarity index 100%
rename from themes/union/layouts/_default/single.html
rename to layouts/_default/single.html
diff --git a/layouts/_default/single.md b/layouts/_default/single.md
new file mode 100644
index 00000000..8cfe35c6
--- /dev/null
+++ b/layouts/_default/single.md
@@ -0,0 +1,22 @@
+{{ define "main" }}
+{{- /*
+Template for generating markdown versions of individual pages.
+This renders the content with shortcodes processed for markdown output.
+*/ -}}
+{{- if .Params.description }}
+
+{{ .Params.description }}
+{{- end }}
+
+{{ .RawContent }}
+
+---
+**Source**: {{ .File.Path }}
+**URL**: {{ .Permalink }}
+{{- if .Date }}
+**Date**: {{ .Date.Format "2006-01-02" }}
+{{- end }}
+{{- if .Params.weight }}
+**Weight**: {{ .Params.weight }}
+{{- end }}
+{{ end }}
\ No newline at end of file
diff --git a/themes/union/layouts/home/sitemap.xml b/layouts/home/sitemap.xml
similarity index 100%
rename from themes/union/layouts/home/sitemap.xml
rename to layouts/home/sitemap.xml
diff --git a/themes/union/layouts/partials/breadcrumb.html b/layouts/partials/breadcrumb.html
similarity index 100%
rename from themes/union/layouts/partials/breadcrumb.html
rename to layouts/partials/breadcrumb.html
diff --git a/themes/union/layouts/partials/flyte-banner.html b/layouts/partials/flyte-banner.html
similarity index 100%
rename from themes/union/layouts/partials/flyte-banner.html
rename to layouts/partials/flyte-banner.html
diff --git a/themes/union/layouts/partials/footer-nav.html b/layouts/partials/footer-nav.html
similarity index 100%
rename from themes/union/layouts/partials/footer-nav.html
rename to layouts/partials/footer-nav.html
diff --git a/themes/union/layouts/partials/header-logo.html b/layouts/partials/header-logo.html
similarity index 100%
rename from themes/union/layouts/partials/header-logo.html
rename to layouts/partials/header-logo.html
diff --git a/themes/union/layouts/partials/header.html b/layouts/partials/header.html
similarity index 100%
rename from themes/union/layouts/partials/header.html
rename to layouts/partials/header.html
diff --git a/themes/union/layouts/partials/no-content.html b/layouts/partials/no-content.html
similarity index 100%
rename from themes/union/layouts/partials/no-content.html
rename to layouts/partials/no-content.html
diff --git a/themes/union/layouts/partials/page-allowed.html b/layouts/partials/page-allowed.html
similarity index 100%
rename from themes/union/layouts/partials/page-allowed.html
rename to layouts/partials/page-allowed.html
diff --git a/themes/union/layouts/partials/page-title.html b/layouts/partials/page-title.html
similarity index 100%
rename from themes/union/layouts/partials/page-title.html
rename to layouts/partials/page-title.html
diff --git a/themes/union/layouts/partials/resource-map.html b/layouts/partials/resource-map.html
similarity index 100%
rename from themes/union/layouts/partials/resource-map.html
rename to layouts/partials/resource-map.html
diff --git a/themes/union/layouts/partials/run-on-union.html b/layouts/partials/run-on-union.html
similarity index 100%
rename from themes/union/layouts/partials/run-on-union.html
rename to layouts/partials/run-on-union.html
diff --git a/themes/union/layouts/partials/run-on-union.md b/layouts/partials/run-on-union.md
similarity index 100%
rename from themes/union/layouts/partials/run-on-union.md
rename to layouts/partials/run-on-union.md
diff --git a/themes/union/layouts/partials/search.html b/layouts/partials/search.html
similarity index 100%
rename from themes/union/layouts/partials/search.html
rename to layouts/partials/search.html
diff --git a/themes/union/layouts/partials/seo-meta.html b/layouts/partials/seo-meta.html
similarity index 100%
rename from themes/union/layouts/partials/seo-meta.html
rename to layouts/partials/seo-meta.html
diff --git a/themes/union/layouts/partials/sidebar.html b/layouts/partials/sidebar.html
similarity index 100%
rename from themes/union/layouts/partials/sidebar.html
rename to layouts/partials/sidebar.html
diff --git a/themes/union/layouts/partials/signup.html b/layouts/partials/signup.html
similarity index 100%
rename from themes/union/layouts/partials/signup.html
rename to layouts/partials/signup.html
diff --git a/themes/union/layouts/partials/tabs.html b/layouts/partials/tabs.html
similarity index 100%
rename from themes/union/layouts/partials/tabs.html
rename to layouts/partials/tabs.html
diff --git a/themes/union/layouts/partials/toc.html b/layouts/partials/toc.html
similarity index 100%
rename from themes/union/layouts/partials/toc.html
rename to layouts/partials/toc.html
diff --git a/themes/union/layouts/partials/variant-selector.html b/layouts/partials/variant-selector.html
similarity index 100%
rename from themes/union/layouts/partials/variant-selector.html
rename to layouts/partials/variant-selector.html
diff --git a/themes/union/layouts/partials/versions.html b/layouts/partials/versions.html
similarity index 100%
rename from themes/union/layouts/partials/versions.html
rename to layouts/partials/versions.html
diff --git a/themes/union/layouts/robots.txt b/layouts/robots.txt
similarity index 100%
rename from themes/union/layouts/robots.txt
rename to layouts/robots.txt
diff --git a/themes/union/layouts/sitemap.xml b/layouts/sitemap.xml
similarity index 100%
rename from themes/union/layouts/sitemap.xml
rename to layouts/sitemap.xml
diff --git a/markdown_tree_analysis.json b/markdown_tree_analysis.json
new file mode 100644
index 00000000..3a6b0549
--- /dev/null
+++ b/markdown_tree_analysis.json
@@ -0,0 +1,352 @@
+{
+  "timestamp": "2025-12-05",
+  "base_path": "/Users/ppiegaze/repos/unionai/unionai-docs",
+  "report": {
+    "total_variants": 3,
+    "variants": {
+      "flyte": {
+        "files": 6,
+        "subpages": 6,
+        "broken_links": 0
+      },
+      "byoc": {
+        "files": 6,
+        "subpages": 6,
+        "broken_links": 0
+      },
+      "selfmanaged": {
+        "files": 6,
+        "subpages": 6,
+        "broken_links": 0
+      }
+    },
+    "summary": {
+      "total_files": 18,
+      "total_subpages": 18,
+      "broken_links": 0
+    }
+  },
+  "trees": {
+    "flyte": {
+      "variant": "flyte",
+      "root_path": "dist/docs/v2/flyte/md/index.md",
+      "tree": {
+        "file_info": {
+          "path": "dist/docs/v2/flyte/md/index.md",
+          "exists": true,
+          "size": 335,
+          "title": "Documentation"
+        },
+        "subpages_count": 6,
+        "subpages": [
+          {
+            "title": "User Guide",
+            "link": "user-guide/index.md",
+            "resolved_path": "dist/docs/v2/flyte/md/user-guide/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/flyte/md/user-guide/index.md",
+                "exists": true,
+                "size": 1281,
+                "title": "Flyte"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Tutorials",
+            "link": "tutorials/index.md",
+            "resolved_path": "dist/docs/v2/flyte/md/tutorials/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/flyte/md/tutorials/index.md",
+                "exists": true,
+                "size": 1508,
+                "title": "Tutorials"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Integrations",
+            "link": "integrations/index.md",
+            "resolved_path": "dist/docs/v2/flyte/md/integrations/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/flyte/md/integrations/index.md",
+                "exists": true,
+                "size": 703,
+                "title": "Integrations"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "API Reference",
+            "link": "api-reference/index.md",
+            "resolved_path": "dist/docs/v2/flyte/md/api-reference/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/flyte/md/api-reference/index.md",
+                "exists": true,
+                "size": 714,
+                "title": "Reference"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Community",
+            "link": "community/index.md",
+            "resolved_path": "dist/docs/v2/flyte/md/community/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/flyte/md/community/index.md",
+                "exists": true,
+                "size": 1574,
+                "title": "Community"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Release Notes",
+            "link": "release-notes.md",
+            "resolved_path": "dist/docs/v2/flyte/md/release-notes.md",
+            "exists": true,
+            "file_info": {
+              "path": "dist/docs/v2/flyte/md/release-notes.md",
+              "exists": true,
+              "size": 96,
+              "title": "Release Notes"
+            }
+          }
+        ]
+      }
+    },
+    "byoc": {
+      "variant": "byoc",
+      "root_path": "dist/docs/v2/byoc/md/index.md",
+      "tree": {
+        "file_info": {
+          "path": "dist/docs/v2/byoc/md/index.md",
+          "exists": true,
+          "size": 334,
+          "title": "Documentation"
+        },
+        "subpages_count": 6,
+        "subpages": [
+          {
+            "title": "User Guide",
+            "link": "user-guide/index.md",
+            "resolved_path": "dist/docs/v2/byoc/md/user-guide/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/byoc/md/user-guide/index.md",
+                "exists": true,
+                "size": 1607,
+                "title": "Union.ai BYOC"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Tutorials",
+            "link": "tutorials/index.md",
+            "resolved_path": "dist/docs/v2/byoc/md/tutorials/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/byoc/md/tutorials/index.md",
+                "exists": true,
+                "size": 1507,
+                "title": "Tutorials"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Integrations",
+            "link": "integrations/index.md",
+            "resolved_path": "dist/docs/v2/byoc/md/integrations/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/byoc/md/integrations/index.md",
+                "exists": true,
+                "size": 702,
+                "title": "Integrations"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "API Reference",
+            "link": "api-reference/index.md",
+            "resolved_path": "dist/docs/v2/byoc/md/api-reference/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/byoc/md/api-reference/index.md",
+                "exists": true,
+                "size": 713,
+                "title": "Reference"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Community",
+            "link": "community/index.md",
+            "resolved_path": "dist/docs/v2/byoc/md/community/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/byoc/md/community/index.md",
+                "exists": true,
+                "size": 1169,
+                "title": "Community"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Release Notes",
+            "link": "release-notes.md",
+            "resolved_path": "dist/docs/v2/byoc/md/release-notes.md",
+            "exists": true,
+            "file_info": {
+              "path": "dist/docs/v2/byoc/md/release-notes.md",
+              "exists": true,
+              "size": 7912,
+              "title": "Release Notes"
+            }
+          }
+        ]
+      }
+    },
+    "selfmanaged": {
+      "variant": "selfmanaged",
+      "root_path": "dist/docs/v2/selfmanaged/md/index.md",
+      "tree": {
+        "file_info": {
+          "path": "dist/docs/v2/selfmanaged/md/index.md",
+          "exists": true,
+          "size": 341,
+          "title": "Documentation"
+        },
+        "subpages_count": 6,
+        "subpages": [
+          {
+            "title": "User Guide",
+            "link": "user-guide/index.md",
+            "resolved_path": "dist/docs/v2/selfmanaged/md/user-guide/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/selfmanaged/md/user-guide/index.md",
+                "exists": true,
+                "size": 1589,
+                "title": "Union.ai Self-managed"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Tutorials",
+            "link": "tutorials/index.md",
+            "resolved_path": "dist/docs/v2/selfmanaged/md/tutorials/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/selfmanaged/md/tutorials/index.md",
+                "exists": true,
+                "size": 1514,
+                "title": "Tutorials"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Integrations",
+            "link": "integrations/index.md",
+            "resolved_path": "dist/docs/v2/selfmanaged/md/integrations/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/selfmanaged/md/integrations/index.md",
+                "exists": true,
+                "size": 709,
+                "title": "Integrations"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "API Reference",
+            "link": "api-reference/index.md",
+            "resolved_path": "dist/docs/v2/selfmanaged/md/api-reference/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/selfmanaged/md/api-reference/index.md",
+                "exists": true,
+                "size": 720,
+                "title": "Reference"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Community",
+            "link": "community/index.md",
+            "resolved_path": "dist/docs/v2/selfmanaged/md/community/index.md",
+            "exists": true,
+            "children": {
+              "file_info": {
+                "path": "dist/docs/v2/selfmanaged/md/community/index.md",
+                "exists": true,
+                "size": 1176,
+                "title": "Community"
+              },
+              "subpages_count": 0,
+              "subpages": []
+            }
+          },
+          {
+            "title": "Release Notes",
+            "link": "release-notes.md",
+            "resolved_path": "dist/docs/v2/selfmanaged/md/release-notes.md",
+            "exists": true,
+            "file_info": {
+              "path": "dist/docs/v2/selfmanaged/md/release-notes.md",
+              "exists": true,
+              "size": 7919,
+              "title": "Release Notes"
+            }
+          }
+        ]
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/meta_descriptions.json b/meta_descriptions.json
index 8035dbd1..4f0888fe 100644
--- a/meta_descriptions.json
+++ b/meta_descriptions.json
@@ -555,42 +555,6 @@
     "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.extras/containertask/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
   },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors/asyncconnector/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors/asyncconnectorexecutormixin/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors/connectorregistry/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors/resource/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors/resourcemeta/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors/connectorservice/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.app.extras/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.app.extras/fastapiappenvironment/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
   {
     "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.storage/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
@@ -611,10 +575,6 @@
     "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.storage/gcs/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
   },
-  {
-    "file_path": "dist/docs/v2/flyte/api-reference/flyte-sdk/packages/flyte.connectors.utils/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
   {
     "file_path": "dist/docs/v2/flyte/tags/index.html",
     "meta_description": "Union.ai documentation for AI workflow orchestration and machine learning pipelines."
@@ -1291,42 +1251,6 @@
     "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.extras/containertask/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
   },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors/asyncconnector/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors/asyncconnectorexecutormixin/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors/connectorregistry/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors/resource/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors/resourcemeta/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors/connectorservice/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.app.extras/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.app.extras/fastapiappenvironment/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
   {
     "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.storage/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
@@ -1347,10 +1271,6 @@
     "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.storage/gcs/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
   },
-  {
-    "file_path": "dist/docs/v2/byoc/api-reference/flyte-sdk/packages/flyte.connectors.utils/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
   {
     "file_path": "dist/docs/v2/byoc/release-notes/index.html",
     "meta_description": "We redesigned the Runs page to better support large numbers of runs. Historically, large projects produced so many runs that flat listings became difficult to â€¦"
@@ -2023,42 +1943,6 @@
     "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.extras/containertask/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
   },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors/asyncconnector/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors/asyncconnectorexecutormixin/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors/connectorregistry/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors/resource/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors/resourcemeta/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors/connectorservice/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.app.extras/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.app.extras/fastapiappenvironment/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
   {
     "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.storage/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
@@ -2079,10 +1963,6 @@
     "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.storage/gcs/index.html",
     "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
   },
-  {
-    "file_path": "dist/docs/v2/selfmanaged/api-reference/flyte-sdk/packages/flyte.connectors.utils/index.html",
-    "meta_description": "API reference documentation for Union.ai workflow orchestration and machine learning pipelines."
-  },
   {
     "file_path": "dist/docs/v2/selfmanaged/release-notes/index.html",
     "meta_description": "We redesigned the Runs page to better support large numbers of runs. Historically, large projects produced so many runs that flat listings became difficult to â€¦"
diff --git a/process_shortcodes.py b/process_shortcodes.py
new file mode 100644
index 00000000..bab1afb9
--- /dev/null
+++ b/process_shortcodes.py
@@ -0,0 +1,1002 @@
+#!/usr/bin/env python3
+"""
+Hugo Shortcode Processor for Markdown Output
+
+This script post-processes Hugo-generated markdown files to convert shortcodes
+into clean markdown equivalents.
+
+Usage:
+    python process_shortcodes.py --variant=byoc --input-dir=dist/docs/v2/byoc/tmp-md --output-dir=dist/docs/v2/byoc/md
+"""
+
+import argparse
+import os
+import re
+from pathlib import Path
+from typing import Dict, Any, Optional
+
+# Handle TOML parsing with fallbacks
+try:
+    import tomllib  # Python 3.11+
+    def load_toml(file_handle):
+        return tomllib.load(file_handle)
+except ImportError:
+    try:
+        import tomli as tomllib
+        def load_toml(file_handle):
+            return tomllib.load(file_handle)
+    except ImportError:
+        try:
+            import toml as tomllib
+            def load_toml(file_handle):
+                return tomllib.load(file_handle)
+        except ImportError:
+            print("Error: No TOML library available. Please install tomli or toml.")
+            def load_toml(file_handle):
+                return {}
+
+
+class ShortcodeProcessor:
+    def __init__(self, variant: str, base_path: str = "", input_dir: str = ""):
+        self.variant = variant
+        self.base_path = Path(base_path) if base_path else Path.cwd()
+        self.input_dir = Path(input_dir) if input_dir else Path.cwd()
+        self.key_mappings = self._load_key_mappings()
+
+    def _load_key_mappings(self) -> Dict[str, Dict[str, str]]:
+        """Load key mappings from hugo.site.toml dynamically."""
+        try:
+            toml_path = self.base_path / "hugo.site.toml"
+            if not toml_path.exists():
+                print(f"Warning: hugo.site.toml not found at {toml_path}")
+                return {}
+
+            # Try binary mode first (for tomllib), then text mode (for toml/tomli)
+            try:
+                with open(toml_path, 'rb') as f:
+                    config = load_toml(f)
+            except (TypeError, UnicodeDecodeError):
+                with open(toml_path, 'r', encoding='utf-8') as f:
+                    config = load_toml(f)
+
+            # Extract key mappings from params.key
+            key_params = config.get('params', {}).get('key', {})
+
+            # Transform the nested structure to a flat mapping per variant
+            mappings = {}
+            variants = ['flyte', 'byoc', 'selfmanaged']
+
+            for variant in variants:
+                mappings[variant] = {}
+                for key_type, variant_values in key_params.items():
+                    if isinstance(variant_values, dict) and variant in variant_values:
+                        mappings[variant][key_type] = variant_values[variant]
+
+            return mappings
+
+        except Exception as e:
+            print(f"Error loading key mappings from hugo.site.toml: {e}")
+            return {}
+
+
+
+
+
+    def process_file(self, file_path: Path) -> str:
+        """Process a single markdown file and return the processed content."""
+        with open(file_path, 'r', encoding='utf-8') as f:
+            content = f.read()
+
+        # Process shortcodes recursively to handle nesting
+        processed_content = self.process_shortcodes_recursive(content)
+
+        # Normalize vertical spacing
+        processed_content = self.normalize_vertical_spacing(processed_content)
+
+        return processed_content
+
+    def normalize_vertical_spacing(self, content: str) -> str:
+        """Normalize vertical spacing to maximum one empty line between blocks and remove leading empty lines."""
+        # Split content into lines
+        lines = content.split('\n')
+        normalized_lines = []
+
+        # Track consecutive empty lines and whether we've found content yet
+        empty_line_count = 0
+        found_content = False
+
+        for line in lines:
+            if line.strip() == '':
+                empty_line_count += 1
+                # Only add empty line if we've found content and haven't exceeded our limit
+                if found_content and empty_line_count <= 1:
+                    normalized_lines.append(line)
+            else:
+                # Reset counter when we hit a non-empty line
+                empty_line_count = 0
+                found_content = True
+                normalized_lines.append(line)
+
+        # Join lines back together and ensure we don't end with multiple empty lines
+        result = '\n'.join(normalized_lines)
+
+        # Remove trailing whitespace and ensure single trailing newline
+        result = result.rstrip() + '\n'
+
+        return result
+
+    def process_shortcodes_recursive(self, content: str, max_depth: int = 10) -> str:
+        """Recursively process shortcodes to handle arbitrary nesting depth."""
+        if max_depth <= 0:
+            return content  # Prevent infinite recursion
+
+        original_content = content
+
+        # Process container shortcodes first (they may contain other shortcodes)
+        content = self.process_variant_shortcodes_recursive(content)
+        content = self.process_markdown_shortcodes_recursive(content)
+        content = self.process_grid_shortcodes_recursive(content)
+        content = self.process_dropdown_shortcodes_recursive(content)
+        content = self.process_tabs_shortcodes_recursive(content)
+
+        # Then process leaf shortcodes
+        content = self.process_code_shortcodes(content)
+        content = self.process_note_shortcodes_recursive(content)
+        content = self.process_warning_shortcodes_recursive(content)
+        content = self.process_link_card_shortcodes_recursive(content)
+        content = self.process_multiline_shortcodes(content)
+        content = self.process_icon_shortcodes(content)
+        content = self.process_button_link_shortcodes_recursive(content)
+        content = self.process_key_shortcodes(content)
+        content = self.process_docs_home_shortcodes(content)
+        content = self.process_download_shortcodes(content)
+        content = self.process_youtube_shortcodes(content)
+
+        # If content changed, recurse to handle any newly exposed shortcodes
+        if content != original_content:
+            content = self.process_shortcodes_recursive(content, max_depth - 1)
+
+        return content
+
+    def process_code_shortcodes(self, content: str) -> str:
+        """Process {{< code file="..." lang="..." >}} shortcodes."""
+        pattern = r'\{\{<\s*code\s+file="([^"]*)"(?:\s+lang="([^"]*)")?(?:\s+fragment="([^"]*)")?[^>]*>\}\}'
+
+        def replace_code(match):
+            file_path, lang, fragment = match.groups()
+
+            # Read file content
+            try:
+                full_path = self.resolve_file_path(file_path)
+                with open(full_path, 'r', encoding='utf-8') as f:
+                    file_content = f.read()
+
+                # Handle fragments if specified
+                if fragment:
+                    file_content = self.extract_fragment(file_content, fragment)
+
+                # Generate markdown code block
+                lang_str = lang or ""
+                return f"```{lang_str}\n{file_content.rstrip()}\n```\n\n*Source: {file_path}*"
+
+            except Exception as e:
+                return f"```\n# Error reading file: {file_path}\n# {str(e)}\n```"
+
+        return re.sub(pattern, replace_code, content)
+
+    def process_note_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< note >}} shortcodes with support for nested shortcodes."""
+        return self.process_note_shortcodes(content)  # Delegate to main function
+
+    def process_note_shortcodes(self, content: str) -> str:
+        """Process {{< note >}} shortcodes."""
+        pattern = r'\{\{<\s*note(?:\s+title="([^"]*)")?[^>]*>\}\}(.*?)\{\{<\s*/note\s*>\}\}'
+
+        def replace_note(match):
+            title, note_content = match.groups()
+            title = title or "Note"
+
+            # Convert to markdown blockquote
+            lines = note_content.strip().split('\n')
+            quoted_lines = [f"> {line}" if line.strip() else ">" for line in lines]
+
+            return f"> **ðŸ“ {title}**\n>\n" + "\n".join(quoted_lines)
+
+        return re.sub(pattern, replace_note, content, flags=re.DOTALL)
+
+    def process_warning_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< warning >}} shortcodes with support for nested shortcodes."""
+        return self.process_warning_shortcodes(content)  # Delegate to main function
+
+    def process_warning_shortcodes(self, content: str) -> str:
+        """Process {{< warning >}} shortcodes."""
+        pattern = r'\{\{<\s*warning(?:\s+title="([^"]*)")?[^>]*>\}\}(.*?)\{\{<\s*/warning\s*>\}\}'
+
+        def replace_warning(match):
+            title, warning_content = match.groups()
+            title = title or "Warning"
+
+            # Convert to markdown blockquote
+            lines = warning_content.strip().split('\n')
+            quoted_lines = [f"> {line}" if line.strip() else ">" for line in lines]
+
+            return f"> **âš ï¸ {title}**\n>\n" + "\n".join(quoted_lines)
+
+        return re.sub(pattern, replace_warning, content, flags=re.DOTALL)
+
+    def process_tabs_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< tabs >}} shortcodes with support for nested shortcodes."""
+        return self.process_tabs_shortcodes(content)  # Delegate to main function
+
+    def process_tabs_shortcodes(self, content: str) -> str:
+        """Process {{< tabs >}} and {{< tab >}} shortcodes."""
+        # First extract all tab content
+        tab_pattern = r'\{\{<\s*tab\s+"([^"]*)"\s*>\}\}(.*?)\{\{<\s*/tab\s*>\}\}'
+        tabs_pattern = r'\{\{<\s*tabs[^>]*>\}\}(.*?)\{\{<\s*/tabs\s*>\}\}'
+
+        def replace_tabs(match):
+            tabs_content = match.group(1)
+
+            # Find all tabs within this tabs block
+            tab_matches = re.findall(tab_pattern, tabs_content, flags=re.DOTALL)
+
+            if not tab_matches:
+                return "<!-- Empty tabs block -->"
+
+            # Convert to markdown with headers
+            result = []
+            for i, (tab_title, tab_content) in enumerate(tab_matches):
+                if i == 0:
+                    result.append(f"### {tab_title}")
+                else:
+                    result.append(f"\n### {tab_title}")
+                result.append(f"\n{tab_content.strip()}\n")
+
+            return "\n".join(result)
+
+        return re.sub(tabs_pattern, replace_tabs, content, flags=re.DOTALL)
+
+    def process_icon_shortcodes(self, content: str) -> str:
+        """Process {{< icon >}} shortcodes."""
+        pattern = r'\{\{<\s*icon\s+"([^"]*)"\s*>\}\}'
+
+        # Icon mapping to unicode equivalents
+        icon_map = {
+            "info-circle": "â„¹ï¸",
+            "exclamation-triangle": "âš ï¸",
+            "check": "âœ…",
+            "times": "âŒ",
+            "arrow-right": "â†’",
+            "arrow-left": "â†",
+            "download": "ðŸ“¥",
+            "upload": "ðŸ“¤",
+            "home": "ðŸ ",
+            "settings": "âš™ï¸",
+            "search": "ðŸ”",
+        }
+
+        def replace_icon(match):
+            icon_name = match.group(1)
+            return icon_map.get(icon_name, f"[{icon_name}]")
+
+        return re.sub(pattern, replace_icon, content)
+
+    def process_button_link_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< button-link >}} shortcodes with support for nested shortcodes."""
+        return self.process_button_link_shortcodes(content)  # Delegate to main function
+
+    def process_button_link_shortcodes(self, content: str) -> str:
+        """Process {{< button-link >}} shortcodes."""
+        pattern = r'\{\{<\s*button-link\s+href="([^"]*)"\s*>\}\}(.*?)\{\{<\s*/button-link\s*>\}\}'
+
+        def replace_button_link(match):
+            href, link_text = match.groups()
+            return f"[{link_text.strip()}]({href})"
+
+        return re.sub(pattern, replace_button_link, content, flags=re.DOTALL)
+
+    def process_variant_shortcodes(self, content: str) -> str:
+        """Process {{< variant >}} shortcodes for conditional content based on variant."""
+        pattern = r'\{\{<\s*variant\s+([^>]*)>\}\}(.*?)\{\{<\s*/variant\s*>\}\}'
+
+        def replace_variant(match):
+            variant_spec, variant_content = match.groups()
+
+            # Parse variant specification (e.g., "byoc selfmanaged" or "!flyte")
+            # Handle space-separated variants and negation
+            variants = [v.strip() for v in variant_spec.split()]
+
+            include_variants = [v for v in variants if not v.startswith('!')]
+            exclude_variants = [v[1:] for v in variants if v.startswith('!')]
+
+            # Check if current variant should include this content
+            should_include = True
+
+            # If there are include variants specified, current variant must be in the list
+            if include_variants:
+                should_include = self.variant in include_variants
+
+            # If there are exclude variants specified, current variant must NOT be in the list
+            if exclude_variants:
+                should_include = should_include and (self.variant not in exclude_variants)
+
+            return variant_content.strip() if should_include else ""
+
+        return re.sub(pattern, replace_variant, content, flags=re.DOTALL)
+
+    def process_variant_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< variant >}} shortcodes with support for nested shortcodes."""
+        return self.process_variant_shortcodes(content)  # Delegate to main function
+
+    def process_markdown_shortcodes(self, content: str) -> str:
+        """Process {{< markdown >}} shortcodes by removing them (they serve no purpose in markdown output)."""
+        # Remove markdown shortcode containers, keeping only the content
+        pattern = r'\{\{<\s*markdown[^>]*>\}\}(.*?)\{\{<\s*/markdown\s*>\}\}'
+
+        def replace_markdown(match):
+            return match.group(1)
+
+        return re.sub(pattern, replace_markdown, content, flags=re.DOTALL)
+
+    def process_markdown_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< markdown >}} shortcodes with support for nested shortcodes."""
+        return self.process_markdown_shortcodes(content)  # Delegate to main function
+
+    def process_grid_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< grid >}} shortcodes with support for nested shortcodes."""
+        return self.process_grid_shortcodes(content)  # Delegate to main function
+
+    def process_grid_shortcodes(self, content: str) -> str:
+        """Process {{< grid >}} shortcodes by converting them to markdown structure."""
+        pattern = r'\{\{<\s*grid[^>]*>\}\}(.*?)\{\{<\s*/grid\s*>\}\}'
+
+        def replace_grid(match):
+            grid_content = match.group(1).strip()
+            # Just return the content without the grid wrapper
+            # The nested shortcodes (like link-card) will be processed separately
+            return grid_content
+
+        return re.sub(pattern, replace_grid, content, flags=re.DOTALL)
+
+    def resolve_file_path(self, file_path: str) -> Path:
+        """Resolve shortcode file paths to actual file system paths."""
+        # Handle different prefixes
+        if file_path.startswith('/external/'):
+            # External files are in the external/ subdirectory
+            return self.base_path / file_path.lstrip('/')
+        elif file_path.startswith('/static/'):
+            return self.base_path / 'static' / file_path[8:]
+        elif file_path.startswith('/_static/'):
+            return self.base_path / 'content' / '_static' / file_path[9:]
+        else:
+            return self.base_path / file_path.lstrip('/')
+
+    def extract_fragment(self, content: str, fragment_name: str) -> str:
+        """Extract a fragment from file content using Hugo fragment markers."""
+        start_marker = f"{{{{docs-fragment {fragment_name}}}}}"
+        end_marker = f"{{{{/docs-fragment {fragment_name}}}}}"
+
+        lines = content.split('\n')
+        in_fragment = False
+        fragment_lines = []
+
+        for line in lines:
+            # Check for markers in comments (removing common comment prefixes)
+            clean_line = re.sub(r'^\s*(#|//|/\*+|\*+)?\s*', '', line)
+
+            if clean_line == start_marker:
+                in_fragment = True
+            elif clean_line == end_marker:
+                break
+            elif in_fragment:
+                fragment_lines.append(line)
+
+        return '\n'.join(fragment_lines)
+
+    def process_grid_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< grid >}} shortcodes with support for nested shortcodes."""
+        return self.process_grid_shortcodes(content)  # Delegate to main function
+
+    def process_grid_shortcodes(self, content: str) -> str:
+        """Process {{< grid >}} shortcodes by converting them to markdown structure."""
+        pattern = r'\{\{<\s*grid[^>]*>\}\}(.*?)\{\{<\s*/grid\s*>\}\}'
+
+        def replace_grid(match):
+            grid_content = match.group(1).strip()
+            # Just return the content without the grid wrapper
+            # The nested shortcodes (like link-card) will be processed separately
+            return grid_content
+
+        return re.sub(pattern, replace_grid, content, flags=re.DOTALL)
+
+    def process_dropdown_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< dropdown >}} shortcodes with support for nested shortcodes."""
+        return self.process_dropdown_shortcodes(content)  # Delegate to main function
+
+    def process_dropdown_shortcodes(self, content: str) -> str:
+        """Process {{< dropdown >}} shortcodes by converting them to markdown collapsible sections."""
+        pattern = r'\{\{<\s*dropdown\s+title="([^"]*?)"[^>]*>\}\}(.*?)\{\{<\s*/dropdown\s*>\}\}'
+
+        def replace_dropdown(match):
+            title, dropdown_content = match.groups()
+            # Convert to markdown collapsible section
+            return f"\n<details>\n<summary>{title}</summary>\n\n{dropdown_content.strip()}\n\n</details>\n"
+
+        return re.sub(pattern, replace_dropdown, content, flags=re.DOTALL)
+
+    def process_link_card_shortcodes_recursive(self, content: str) -> str:
+        """Process {{< link-card >}} shortcodes with support for nested shortcodes."""
+        return self.process_link_card_shortcodes(content)  # Delegate to main function
+
+    def process_link_card_shortcodes(self, content: str) -> str:
+        """Process {{< link-card >}} shortcodes by converting them to markdown links."""
+        pattern = r'\{\{<\s*link-card\s+target="([^"]*)"\s*(?:icon="([^"]*)")?\s*(?:title="([^"]*)")?\s*[^>]*>\}\}(.*?)\{\{<\s*/link-card\s*>\}\}'
+
+        def replace_link_card(match):
+            target, icon, title, card_content = match.groups()
+
+            # Convert icon to emoji if available
+            icon_map = {
+                "lightbulb": "ðŸ’¡",
+                "123": "ðŸ”¢",
+                "book": "ðŸ“š",
+                "code": "ðŸ’»",
+                "settings": "âš™ï¸",
+                "rocket": "ðŸš€",
+                "chart": "ðŸ“Š"
+            }
+            icon_emoji = icon_map.get(icon, "ðŸ”—") if icon else "ðŸ”—"
+
+            # Create markdown card representation
+            title = title or "Link"
+            # Use target URL as-is
+            return f"\n### {icon_emoji} [{title}]({target})\n\n{card_content.strip()}\n"
+
+        return re.sub(pattern, replace_link_card, content, flags=re.DOTALL)
+
+    def process_multiline_shortcodes(self, content: str) -> str:
+        """Process {{< multiline >}} shortcodes by preserving the content without formatting."""
+        pattern = r'\{\{<\s*multiline[^>]*>\}\}(.*?)\{\{<\s*/multiline\s*>\}\}'
+
+        def replace_multiline(match):
+            multiline_content = match.group(1).strip()
+            # For multiline content (often CLI options), just return the content
+            # This preserves line breaks and formatting
+            return multiline_content
+
+        return re.sub(pattern, replace_multiline, content, flags=re.DOTALL)
+
+    def process_key_shortcodes(self, content: str) -> str:
+        """Process {{< key >}} shortcodes by replacing them with variant-specific values."""
+        pattern = r'\{\{<\s*key\s+([^>]*)\s*>\}\}'
+
+        def replace_key(match):
+            key_name = match.group(1).strip()
+
+            # Get the mapping for the current variant from dynamically loaded config
+            variant_mappings = self.key_mappings.get(self.variant, {})
+
+            # Return the mapped value or the key name if not found
+            return variant_mappings.get(key_name, f"{{{{< key {key_name} >}}}}")
+
+        return re.sub(pattern, replace_key, content)
+
+    def process_docs_home_shortcodes(self, content: str) -> str:
+        """Process {{< docs_home >}} shortcodes by creating variant-specific links."""
+        pattern = r'\{\{<\s*docs_home\s+([^>]*)\s*>\}\}'
+
+        def replace_docs_home(match):
+            args = match.group(1).strip().split()
+            if len(args) >= 2:
+                variant = args[0]
+                version = args[1]
+                url = f"/docs/{version}/{variant}/"
+            elif len(args) >= 1:
+                variant = args[0]
+                url = f"/docs/v2/{variant}/"
+            else:
+                url = "/docs/"
+            return url
+
+        return re.sub(pattern, replace_docs_home, content)
+
+    def process_download_shortcodes(self, content: str) -> str:
+        """Process {{< download >}} shortcodes by creating markdown download links."""
+        # Match both positional and named parameter formats
+        pattern = r'\{\{<\s*download\s+([^>]*)\s*>\}\}'
+
+        def replace_download(match):
+            params = match.group(1).strip()
+
+            # Parse parameters
+            url = None
+            name = None
+            description = None
+            display = None
+
+            # Handle named parameters
+            if 'file=' in params:
+                url_match = re.search(r'file="([^"]*)"|file=\'([^\']*)\'|file=([^\s]+)', params)
+                if url_match:
+                    url = url_match.group(1) or url_match.group(2) or url_match.group(3)
+
+            # Handle positional parameters
+            if not url:
+                parts = re.findall(r'"([^"]*)"|\s*([^\s"]+)', params)
+                flat_parts = [p[0] if p[0] else p[1] for p in parts if p[0] or p[1]]
+                if len(flat_parts) > 0:
+                    url = flat_parts[0]
+                if len(flat_parts) > 1:
+                    name = flat_parts[1]
+                if len(flat_parts) > 2:
+                    description = flat_parts[2]
+
+            # Check for display parameter
+            display_match = re.search(r'display="([^"]*)"|display=\'([^\']*)\'|display=([^\s]+)', params)
+            if display_match:
+                display = display_match.group(1) or display_match.group(2) or display_match.group(3)
+
+            if not url:
+                return match.group(0)  # Return original if no URL found
+
+            # Default name to filename if not provided
+            if not name:
+                name = url.split('/')[-1] if '/' in url else url
+
+            # Create markdown link
+            # Use URL as-is
+            download_link = f"ðŸ“¥ [{name}]({url})"
+
+            # Add description if provided
+            if description:
+                if display == "paragraph":
+                    return f"\n**{download_link}**\n\n*{description}*\n"
+                else:
+                    return f"{download_link} - {description}"
+            else:
+                if display == "paragraph":
+                    return f"\n**{download_link}**\n"
+                else:
+                    return download_link
+
+        return re.sub(pattern, replace_download, content)
+
+    def process_youtube_shortcodes(self, content: str) -> str:
+        """Process {{< youtube >}} shortcodes by creating markdown YouTube links."""
+        pattern = r'\{\{<\s*youtube\s+([^>]*)\s*>\}\}'
+
+        def replace_youtube(match):
+            video_id = match.group(1).strip()
+            # Remove quotes if present
+            video_id = video_id.strip('"\'')
+
+            # Create markdown link to YouTube video
+            youtube_url = f"https://www.youtube.com/watch?v={video_id}"
+            return f"ðŸ“º [Watch on YouTube]({youtube_url})"
+
+        return re.sub(pattern, replace_youtube, content)
+
+    def process_internal_links(self, content: str, current_file_path: Path) -> str:
+        """Convert Hugo-style internal links to proper .md file references."""
+        # Pattern to match markdown links that are not external (don't start with http/https/mailto/etc)
+        link_pattern = r'\[([^\]]*)\]\(([^)]+)\)'
+
+        def replace_link(match):
+            link_text, link_url = match.groups()
+
+            # Skip external links (http/https/mailto/ftp/etc)
+            if re.match(r'^[a-zA-Z][a-zA-Z0-9+.-]*:', link_url):
+                return match.group(0)
+
+            # Skip anchor-only links
+            if link_url.startswith('#'):
+                return match.group(0)
+
+            # Split URL and anchor
+            url_parts = link_url.split('#', 1)
+            base_url = url_parts[0]
+            anchor = '#' + url_parts[1] if len(url_parts) > 1 else ''
+
+            if not base_url:  # Empty base URL means anchor-only
+                return match.group(0)
+
+            # Convert Hugo-style path to final .md file reference
+            current_dir = current_file_path.parent
+            try:
+                if base_url.startswith('/'):
+                    # Absolute path from site root - convert to relative
+                    site_root = Path('dist/docs/v2') / self.variant / 'md'
+                    target_path = site_root / base_url.lstrip('/')
+                else:
+                    # Relative path from current file
+                    target_path = (current_dir / base_url).resolve()
+
+                # Predict what the final structure will look like after processing
+                # We need to determine if this will be a single page or section page
+
+                # First, check if there's a directory - this means it will be a section with index.md
+                if target_path.exists() and target_path.is_dir():
+                    # Will be a directory with index.md
+                    rel_path = os.path.relpath(target_path / 'index.md', current_dir)
+                    return f'[{link_text}]({rel_path}{anchor})'
+
+                # If target_path doesn't exist as directory, it might become a single .md file
+                # Check if there would be a corresponding .md file
+                parent_dir = target_path.parent
+                target_name = target_path.name
+
+                # Check if there will be a {name}.md file in the parent directory
+                potential_md_file = parent_dir / f"{target_name}.md"
+                potential_index_dir = parent_dir / target_name
+
+                # Priority: if there's a directory with that name, it becomes {dir}/index.md
+                if potential_index_dir.exists() and potential_index_dir.is_dir():
+                    rel_path = os.path.relpath(potential_index_dir / 'index.md', current_dir)
+                    return f'[{link_text}]({rel_path}{anchor})'
+
+                # Otherwise, assume it will become {name}.md
+                rel_path = os.path.relpath(potential_md_file, current_dir)
+                return f'[{link_text}]({rel_path}{anchor})'
+
+            except Exception as e:
+                print(f"Error processing link '{link_url}' in {current_file_path}: {e}")
+                return match.group(0)
+
+            except Exception as e:
+                print(f"Error processing link '{link_url}' in {current_file_path}: {e}")
+                return match.group(0)
+
+        return re.sub(link_pattern, replace_link, content)
+
+
+def main():
+    parser = argparse.ArgumentParser(description='Process Hugo shortcodes in markdown files')
+    parser.add_argument('--variant', required=True, help='Site variant (e.g., byoc, flyte)')
+    parser.add_argument('--input-dir', required=True, help='Input directory with markdown files')
+    parser.add_argument('--output-dir', required=True, help='Output directory for processed files')
+    parser.add_argument('--base-path', help='Base path for resolving file references', default='')
+
+    args = parser.parse_args()
+
+    input_dir = Path(args.input_dir)
+    output_dir = Path(args.output_dir)
+
+    if not input_dir.exists():
+        print(f"Error: Input directory {input_dir} does not exist")
+        return 1
+
+    # Create output directory (clear it first if it exists)
+    if output_dir.exists():
+        import shutil
+        shutil.rmtree(output_dir)
+    output_dir.mkdir(parents=True, exist_ok=True)
+
+    processor = ShortcodeProcessor(args.variant, args.base_path, args.input_dir)
+
+    # Process all markdown files
+    for md_file in input_dir.rglob('*.txt'):  # Hugo outputs .txt for MD format
+        # Calculate relative path to preserve directory structure
+        rel_path = md_file.relative_to(input_dir)
+
+        # Skip files not useful in markdown documentation context
+        if (str(rel_path) == '404/index.txt' or
+            rel_path.name == '404.txt' or
+            str(rel_path).startswith('__docs_builder__/')):
+            continue
+
+        # Change .txt extension to .md for output
+        output_rel_path = rel_path.with_suffix('.md')
+        output_file = output_dir / output_rel_path
+
+        # Create output directory if needed
+        output_file.parent.mkdir(parents=True, exist_ok=True)
+
+        print(f"Processing: {rel_path} -> {output_rel_path}")
+
+        try:
+            processed_content = processor.process_file(md_file)
+
+            with open(output_file, 'w', encoding='utf-8') as f:
+                f.write(processed_content)
+
+        except Exception as e:
+            print(f"Error processing {rel_path}: {e}")
+
+    # Create root index.md if it doesn't exist
+    root_index = output_dir / 'index.md'
+    if not root_index.exists():
+        print("Creating root index.md...")
+
+        # Get top-level directories to list in root navigation
+        top_level_dirs = []
+        for item in output_dir.iterdir():
+            if item.is_dir() and not item.name.startswith('_') and item.name != '404':
+                top_level_dirs.append(item.name)
+
+        # Sort directories by priority (User Guide first, Release Notes last)
+        def get_priority(dirname):
+            priority_map = {
+                'user-guide': 1,
+                'tutorials': 2,
+                'integrations': 3,
+                'api-reference': 4,
+                'community': 5,
+                'release-notes': 6
+            }
+            return priority_map.get(dirname, 999)  # Unknown sections go to end
+
+        top_level_dirs.sort(key=get_priority)
+
+        # Create root index content
+        root_content = f"""# Documentation
+
+Welcome to the documentation.
+
+## Subpages
+
+"""
+
+        for dir_name in top_level_dirs:
+            # Convert directory names to proper titles
+            title = dir_name.replace('-', ' ').title()
+            if dir_name == 'user-guide':
+                title = 'User Guide'
+            elif dir_name == 'api-reference':
+                title = 'API Reference'
+            elif dir_name == 'release-notes':
+                title = 'Release Notes'
+
+            root_content += f"- [{title}]({dir_name}/)\n"
+
+        root_content += f"""
+---
+**Source**: _index.md
+**URL**: /docs/v2/{args.variant}/
+"""
+
+        with open(root_index, 'w', encoding='utf-8') as f:
+            f.write(root_content)
+
+    # Restructure single pages (directories with only index.txt)
+    # to be named files instead of directory/index.txt
+    restructure_single_pages(output_dir)
+
+    # Now that the final structure is in place, fix all internal links
+    print("Converting internal links to proper .md references...")
+    fix_internal_links_post_processing(output_dir, args.variant)
+
+    # Check that all internal links have been properly converted
+    check_internal_links(output_dir)
+
+    print(f"Processing complete. Output in: {output_dir}")
+    return 0
+
+
+def restructure_single_pages(output_dir: Path):
+    """
+    Restructure single pages from {dir}/index.md to {parent}/{dirname}.md
+    for directories that only contain index.md (no subdirectories or other files).
+    """
+    print("Restructuring single pages...")
+
+    # Find all directories that contain only index.md
+    single_page_dirs = []
+
+    for root, dirs, files in os.walk(output_dir):
+        root_path = Path(root)
+
+        # Skip the root output directory itself
+        if root_path == output_dir:
+            continue
+
+        # Check if this directory contains only index.md
+        if len(files) == 1 and files[0] == 'index.md' and len(dirs) == 0:
+            single_page_dirs.append(root_path)
+
+    # Process each single page directory
+    for dir_path in single_page_dirs:
+        index_file = dir_path / 'index.md'
+        parent_dir = dir_path.parent
+        new_filename = f"{dir_path.name}.md"
+        new_file_path = parent_dir / new_filename
+
+        print(f"  Moving {index_file.relative_to(output_dir)} -> {new_file_path.relative_to(output_dir)}")
+
+        try:
+            # Move the index.md to the new location
+            index_file.rename(new_file_path)
+
+            # Remove the now-empty directory
+            dir_path.rmdir()
+
+        except Exception as e:
+            print(f"    Error restructuring {dir_path}: {e}")
+
+
+def fix_internal_links_post_processing(output_dir: Path, variant: str):
+    """
+    Fix all internal links after the final file structure is in place.
+    """
+    link_pattern = r'\[([^\]]*)\]\(([^)]+)\)'
+    fixed_count = 0
+    total_files = 0
+
+    for md_file in output_dir.rglob('*.md'):
+        total_files += 1
+        try:
+            with open(md_file, 'r', encoding='utf-8') as f:
+                content = f.read()
+
+            original_content = content
+
+            def replace_link(match):
+                nonlocal fixed_count
+                link_text, link_url = match.groups()
+
+                # Skip external links (http/https/mailto/ftp/etc)
+                if re.match(r'^[a-zA-Z][a-zA-Z0-9+.-]*:', link_url):
+                    return match.group(0)
+
+                # Skip anchor-only links
+                if link_url.startswith('#'):
+                    return match.group(0)
+
+                # Split URL and anchor
+                url_parts = link_url.split('#', 1)
+                base_url = url_parts[0]
+                anchor = '#' + url_parts[1] if len(url_parts) > 1 else ''
+
+                if not base_url:  # Empty base URL means anchor-only
+                    return match.group(0)
+
+                # Skip if it already points to a .md file
+                if base_url.endswith('.md'):
+                    return match.group(0)
+
+                # Convert Hugo-style path to final .md file reference
+                current_dir = md_file.parent
+                try:
+                    if base_url.startswith('/'):
+                        # Absolute path - convert to relative from current file
+                        base_url = base_url.lstrip('/')
+                        target_path = output_dir / base_url
+                    else:
+                        # Relative path from current file
+                        target_path = (current_dir / base_url).resolve()
+
+                    # Now check what actually exists in the final structure
+                    if target_path.exists():
+                        if target_path.is_dir():
+                            # Directory exists, link to index.md
+                            if (target_path / 'index.md').exists():
+                                rel_path = os.path.relpath(target_path / 'index.md', current_dir)
+                                fixed_count += 1
+                                return f'[{link_text}]({rel_path}{anchor})'
+                        elif target_path.is_file() and target_path.suffix == '.md':
+                            # .md file exists
+                            rel_path = os.path.relpath(target_path, current_dir)
+                            fixed_count += 1
+                            return f'[{link_text}]({rel_path}{anchor})'
+
+                    # Check if there's a corresponding .md file
+                    md_file_path = target_path.with_suffix('.md')
+                    if md_file_path.exists():
+                        rel_path = os.path.relpath(md_file_path, current_dir)
+                        fixed_count += 1
+                        return f'[{link_text}]({rel_path}{anchor})'
+
+                    # Check if there's a directory with index.md
+                    if (target_path / 'index.md').exists():
+                        rel_path = os.path.relpath(target_path / 'index.md', current_dir)
+                        fixed_count += 1
+                        return f'[{link_text}]({rel_path}{anchor})'
+
+                    # Special handling for directory links (ending with /)
+                    if base_url.endswith('/'):
+                        dir_path = target_path.parent / target_path.name.rstrip('/')
+                        if (dir_path / 'index.md').exists():
+                            rel_path = os.path.relpath(dir_path / 'index.md', current_dir)
+                            fixed_count += 1
+                            return f'[{link_text}]({rel_path}{anchor})'
+
+                except Exception as e:
+                    pass
+
+                # If we can't resolve it, keep the original
+                return match.group(0)
+
+            # Apply the replacements
+            content = re.sub(link_pattern, replace_link, content)
+
+            # Write back if changed
+            if content != original_content:
+                with open(md_file, 'w', encoding='utf-8') as f:
+                    f.write(content)
+
+        except Exception as e:
+            print(f"Error fixing links in {md_file.relative_to(output_dir)}: {e}")
+
+    print(f"Fixed {fixed_count} internal links across {total_files} files")
+
+
+def check_internal_links(output_dir: Path):
+    """
+    Check that all internal links in the processed markdown files point to actual files.
+    """
+    print("Checking internal links...")
+
+    issues = []
+    total_links = 0
+    valid_links = 0
+
+    # Pattern to match markdown links that are not external
+    link_pattern = r'\[([^\]]*)\]\(([^)]+)\)'
+
+    for md_file in output_dir.rglob('*.md'):
+        try:
+            with open(md_file, 'r', encoding='utf-8') as f:
+                content = f.read()
+
+            for match in re.finditer(link_pattern, content):
+                link_text, link_url = match.groups()
+                total_links += 1
+
+                # Skip external links (http/https/mailto/ftp/etc)
+                if re.match(r'^[a-zA-Z][a-zA-Z0-9+.-]*:', link_url):
+                    valid_links += 1
+                    continue
+
+                # Skip anchor-only links
+                if link_url.startswith('#'):
+                    valid_links += 1
+                    continue
+
+                # Check if link points to an actual file
+                url_parts = link_url.split('#', 1)
+                base_url = url_parts[0]
+
+                if not base_url:  # Empty base URL means anchor-only
+                    valid_links += 1
+                    continue
+
+                # Resolve the link relative to the current file
+                current_dir = md_file.parent
+                try:
+                    if base_url.startswith('/'):
+                        # Absolute path - this shouldn't happen in our processed files
+                        issues.append(f"{md_file.relative_to(output_dir)}: Absolute path link '{link_url}'")
+                        continue
+                    else:
+                        # Relative path from current file
+                        target_path = (current_dir / base_url).resolve()
+
+                    # Check if target exists
+                    if target_path.exists() and target_path.is_file():
+                        if target_path.suffix == '.md':
+                            valid_links += 1
+                        else:
+                            issues.append(f"{md_file.relative_to(output_dir)}: Link points to non-markdown file '{link_url}' -> {target_path.relative_to(output_dir)}")
+                    else:
+                        issues.append(f"{md_file.relative_to(output_dir)}: Broken link '{link_url}' -> target not found")
+
+                except Exception as e:
+                    issues.append(f"{md_file.relative_to(output_dir)}: Error checking link '{link_url}': {e}")
+
+        except Exception as e:
+            issues.append(f"Error reading {md_file.relative_to(output_dir)}: {e}")
+
+    # Report results
+    print(f"Link check complete: {valid_links}/{total_links} links are valid")
+
+    if issues:
+        print(f"Found {len(issues)} link issues:")
+        for issue in issues[:20]:  # Show first 20 issues
+            print(f"  {issue}")
+        if len(issues) > 20:
+            print(f"  ... and {len(issues) - 20} more issues")
+    else:
+        print("âœ… All internal links are properly formatted and point to existing files!")
+
+
+if __name__ == '__main__':
+    exit(main())
\ No newline at end of file
diff --git a/pyproject.toml b/pyproject.toml
new file mode 100644
index 00000000..f4d50fd5
--- /dev/null
+++ b/pyproject.toml
@@ -0,0 +1,15 @@
+[project]
+name = "unionai-docs-tools"
+version = "0.1.0"
+description = "Documentation build tools for Union.ai"
+requires-python = ">=3.8"
+dependencies = [
+    "toml>=0.10.2",
+]
+
+[build-system]
+requires = ["setuptools", "wheel"]
+build-backend = "setuptools.build_meta"
+
+[tool.setuptools]
+py-modules = []
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
new file mode 100644
index 00000000..9a3f6e5c
--- /dev/null
+++ b/requirements.txt
@@ -0,0 +1 @@
+toml>=0.10.2
\ No newline at end of file
diff --git a/static/llms.txt b/static/llms.txt
deleted file mode 100644
index b39262cf..00000000
--- a/static/llms.txt
+++ /dev/null
@@ -1,72 +0,0 @@
-# Flyte
-
-> Flyte is a free and open source platform for orchestrating AI workflows. Flyte empowers AI development teams to rapidly ship high-quality code to production by offering optimized performance, unparalleled resource efficiency, and a delightful workflow authoring experience. Union.ai offers commercial products built on Flyte: BYOC (Bring Your Own Cloud), Self-managed, and Serverless.
-
-Important notes:
-
-- Flyte 2.0 (currently in beta) represents a fundamental shift in how AI workflows are written and executed, with pure Python execution, a simplified API, and fine-grained reproducibility.
-- The Flyte SDK uses Python 3.10+ and integrates with the `uv` package manager.
-- Tasks are defined within `TaskEnvironment` objects, which encapsulate the context and resources needed for execution.
-- There is no `@workflow` decorator in Flyte 2â€”"workflows" are authored through a pattern of tasks calling tasks.
-- Union.ai provides commercial variants with additional features like reusable containers and multi-cluster support.
-
-## Getting Started
-
-- [Getting started](https://www.union.ai/docs/v2/flyte/user-guide/getting-started/): Install Flyte 2, configure your IDE, create and run your first task in minutes.
-- [Flyte 2 introduction](https://www.union.ai/docs/v2/flyte/user-guide/flyte-2/): Learn about pure Python execution, simplified API, improved remote functionality, and native notebook support.
-
-## User Guide - Task Configuration
-
-- [Task configuration overview](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/): Understanding TaskEnvironment, decorator, and invocation-level configuration parameters.
-- [Container images](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/container-images/): Specifying Docker images for task containers.
-- [Resources](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/resources/): Configuring CPU, memory, and GPU requirements.
-- [Caching](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/caching/): Using task-level caching for reproducibility and efficiency.
-- [Secrets](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/secrets/): Managing sensitive data like API keys and credentials.
-- [Retries and timeouts](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/retries-and-timeouts/): Configuring retry strategies and timeout policies.
-- [Triggers](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/triggers/): Setting up event-based and scheduled workflow execution.
-- [Pod templates](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/pod-templates/): Customizing Kubernetes pod configurations.
-- [Reusable containers](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/reusable-containers/): Achieving millisecond-level execution with container reuse (Union.ai feature).
-- [Multiple environments](https://www.union.ai/docs/v2/flyte/user-guide/task-configuration/multiple-environments/): Managing multiple TaskEnvironments in a single workflow.
-
-## User Guide - Task Programming
-
-- [Task programming overview](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/): Essential programming patterns for building robust Flyte workflows.
-- [Files and directories](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/files-and-directories/): Working with large datasets using flyte.File and flyte.Dir.
-- [Dataframes](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/dataframes/): Using pandas, Polars, and other dataframe libraries.
-- [Dataclasses and structures](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/dataclasses-and-structures/): Type-safe workflows with Python dataclasses and Pydantic models.
-- [Fanout](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/fanout/): Parallel execution patterns with asyncio.gather for processing multiple items.
-- [Grouping actions](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/grouping-actions/): Organizing task executions into logical groups.
-- [Notebooks](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/notebooks/): Authoring and running workflows directly in Jupyter notebooks.
-- [Reports](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/reports/): Generating custom HTML reports for visualization in the UI.
-- [Traces](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/traces/): Fine-grained observability and checkpointing with @flyte.trace.
-- [Error handling](https://www.union.ai/docs/v2/flyte/user-guide/task-programming/error-handling/): Robust error recovery with Python try-except and resource scaling.
-
-## Tutorials
-
-- [Multi-agent trading simulation](https://www.union.ai/docs/v2/flyte/tutorials/trading-agents/): A multi-agent trading simulation modeling how agents within a firm interact, strategize, and make trades collaboratively.
-- [Code agent](https://www.union.ai/docs/v2/flyte/tutorials/code-agent/): Securely execute and iterate on LLM-generated code using a code agent with error reflection and retry logic.
-- [Deep research](https://www.union.ai/docs/v2/flyte/tutorials/deep-research/): Build an agentic workflow for deep research with multi-step reasoning and evaluation.
-- [Hyperparameter optimization](https://www.union.ai/docs/v2/flyte/tutorials/hpo/): Run large-scale HPO experiments with zero manual tracking, deterministic results, and automatic recovery.
-- [Automatic prompt engineering](https://www.union.ai/docs/v2/flyte/tutorials/auto_prompt_engineering/): Easily run prompt optimization with real-time observability, traceability, and automatic recovery.
-- [Text-to-SQL](https://www.union.ai/docs/v2/flyte/tutorials/text_to_sql/): Learn how to turn natural language questions into SQL queries with Flyte and LlamaIndex.
-
-## API Reference
-
-- [Flyte SDK](https://www.union.ai/docs/v2/flyte/api-reference/flyte-sdk/): Complete Python API reference for the Flyte SDK including TaskEnvironment, decorators, types, and utilities.
-- [Flyte CLI](https://www.union.ai/docs/v2/flyte/api-reference/flyte-cli/): Command-line interface reference for flyte run, flyte deploy, flyte create config, and other CLI commands.
-- [Flyte LLM context](https://www.union.ai/docs/v2/flyte/api-reference/flyte-context/): LLM context document for AI-based IDEs and assistants to help them better understand Flyte 2 development.
-
-## Integrations
-
-- [Integrations](https://www.union.ai/docs/v2/flyte/integrations/): Flyte plugins and third-party integrations.
-- [Flyte plugins](https://www.union.ai/docs/v2/flyte/integrations/flyte-plugins/): Flyte plugins for Ray, Spark, and OpenAI.
-- [OpenAI](https://www.union.ai/docs/v2/flyte/integrations/flyte-plugins/openai/): Integration with OpenAI's SDKs to build LLM-powered workflows and agentic applications on Flyte.
-- [Ray](https://www.union.ai/docs/v2/flyte/integrations/flyte-plugins/ray/): Run Ray jobs from within Flyte workflows.
-- [Spark](https://www.union.ai/docs/v2/flyte/integrations/flyte-plugins/spark/): Run Spark jobs from within Flyte workflows.
-
-## Community
-
-- [Community](https://www.union.ai/docs/v2/flyte/community/): Information about the Flyte open source community and how to get involved
-- [Contributing code](https://www.union.ai/docs/v2/flyte/community/contributing-code/): Guidelines for contributing to the Flyte codebase
-- [Contributing docs](https://www.union.ai/docs/v2/flyte/community/contributing-docs/): Guidelines for contributing to documentation and examples
-- [Joining the community](https://www.union.ai/docs/v2/flyte/community/joining-the-community/): How to connect with the Flyte community via Slack, GitHub, and community calls
diff --git a/themes/union/markdown/markdown.tmpl b/templates/markdown.tmpl
similarity index 100%
rename from themes/union/markdown/markdown.tmpl
rename to templates/markdown.tmpl
diff --git a/test_link_processing.py b/test_link_processing.py
new file mode 100644
index 00000000..2a2652cb
--- /dev/null
+++ b/test_link_processing.py
@@ -0,0 +1,57 @@
+#!/usr/bin/env python3
+
+# Quick test of the link processing function
+import re
+
+def build_hierarchical_title(url: str, current_path: str, link_text: str) -> str:
+    """Build a hierarchical title from URL path."""
+    # Clean the URL
+    clean_url = url.replace('../', '').replace('./', '').replace('.md', '')
+
+    # Handle index files
+    if clean_url.endswith('/index'):
+        clean_url = clean_url.replace('/index', '')
+
+    # Split into path segments
+    segments = [seg for seg in clean_url.split('/') if seg]
+
+    if not segments:
+        return link_text
+
+    # Build hierarchical title
+    title_parts = []
+    for segment in segments:
+        # Convert kebab-case and snake_case to title case
+        part = segment.replace('-', ' ').replace('_', ' ').title()
+        title_parts.append(part)
+
+    # Use the original link text for the final part if it's more descriptive
+    if len(title_parts) > 0 and link_text.strip() and link_text != title_parts[-1]:
+        title_parts[-1] = link_text.strip()
+
+    return ' > '.join(title_parts)
+
+# Test cases
+test_links = [
+    ("[Getting started](../getting-started/index.md)", "user-guide/flyte-2/index.md"),
+    ("[Local setup](local-setup.md)", "user-guide/getting-started/index.md"),
+    ("[Flyte CLI reference](../../api-reference/flyte-cli.md)", "user-guide/task-configuration/secrets.md"),
+    ("[Image object](../../api-reference/flyte-sdk/packages/flyte/image.md)", "user-guide/task-configuration/container-images.md"),
+    ("[Secrets](secrets.md)", "user-guide/task-configuration/index.md"),
+]
+
+print("Link transformation examples:")
+print("=" * 50)
+
+for link_text, current_path in test_links:
+    # Extract link components
+    match = re.search(r'\[([^\]]+)\]\(([^)]+)\)', link_text)
+    if match:
+        text = match.group(1)
+        url = match.group(2)
+
+        hierarchical = build_hierarchical_title(url, current_path, text)
+
+        print(f"Original: {link_text}")
+        print(f"Result:   **{hierarchical}**")
+        print()
\ No newline at end of file
diff --git a/test_markdown_tree.py b/test_markdown_tree.py
new file mode 100755
index 00000000..9daceed4
--- /dev/null
+++ b/test_markdown_tree.py
@@ -0,0 +1,427 @@
+#!/usr/bin/env python3
+"""
+Test script to regenerate markdown documentation and build a complete JSON tree
+by traversing the ## Subpages links in each index.md file.
+
+Usage:
+    python test_markdown_tree.py
+"""
+
+import json
+import os
+import re
+import subprocess
+import sys
+from pathlib import Path
+from typing import Dict, List, Optional, Set
+
+class MarkdownTreeBuilder:
+    def __init__(self, base_path: Path):
+        self.base_path = base_path
+        self.visited_files: Set[str] = set()
+
+    def run_make_dist(self) -> bool:
+        """Run make dist to regenerate all documentation variants."""
+        print("ðŸ”§ Running 'make dist' to regenerate documentation...")
+        try:
+            result = subprocess.run(['make', 'dist'],
+                                  cwd=self.base_path,
+                                  capture_output=True,
+                                  text=True,
+                                  timeout=300)
+            if result.returncode == 0:
+                print("âœ… Successfully regenerated documentation")
+                return True
+            else:
+                print(f"âŒ Make dist failed with return code {result.returncode}")
+                print(f"STDOUT: {result.stdout}")
+                print(f"STDERR: {result.stderr}")
+                return False
+        except subprocess.TimeoutExpired:
+            print("âŒ Make dist timed out after 5 minutes")
+            return False
+        except Exception as e:
+            print(f"âŒ Error running make dist: {e}")
+            return False
+
+    def find_variants(self) -> List[str]:
+        """Find all available variants in the dist directory."""
+        variants = []
+        dist_path = self.base_path / "dist" / "docs" / "v2"
+
+        if not dist_path.exists():
+            print(f"âŒ Distribution directory not found: {dist_path}")
+            return variants
+
+        for item in dist_path.iterdir():
+            if item.is_dir() and (item / "md" / "index.md").exists():
+                variants.append(item.name)
+
+        print(f"ðŸ“‹ Found variants: {variants}")
+        return variants
+
+    def extract_subpages_links(self, md_file: Path) -> List[Dict[str, str]]:
+        """Extract links from the ## Subpages section of a markdown file."""
+        if not md_file.exists():
+            return []
+
+        try:
+            with open(md_file, 'r', encoding='utf-8') as f:
+                content = f.read()
+        except Exception as e:
+            print(f"âš ï¸  Error reading {md_file}: {e}")
+            return []
+
+        # Find the ## Subpages section
+        subpages_match = re.search(r'^## Subpages\s*\n\n(.*?)(?=\n##|\n---|\Z)',
+                                 content, re.MULTILINE | re.DOTALL)
+
+        if not subpages_match:
+            return []
+
+        subpages_content = subpages_match.group(1).strip()
+
+        # Extract markdown links from the subpages section
+        link_pattern = r'- \[([^\]]+)\]\(([^)]+)\)'
+        links = []
+
+        for match in re.finditer(link_pattern, subpages_content):
+            title = match.group(1)
+            link = match.group(2)
+            links.append({
+                'title': title,
+                'link': link
+            })
+
+        return links
+
+    def resolve_link_path(self, current_dir: Path, link: str) -> Optional[Path]:
+        """Resolve a link relative to the current directory."""
+        # Remove any anchors
+        link = link.split('#')[0]
+
+        # Handle different link formats
+        if link.startswith('/'):
+            # Absolute link - resolve from md root
+            md_root = self.find_md_root(current_dir)
+            if md_root:
+                return (md_root / link.lstrip('/')).resolve()
+        else:
+            # Relative link
+            target = (current_dir / link).resolve()
+
+            # If link doesn't end with .md, it might be a directory
+            if not link.endswith('.md'):
+                # Check for directory with index.md
+                if (target / 'index.md').exists():
+                    return target / 'index.md'
+                # Check for .md file with same name
+                md_file = target.with_suffix('.md')
+                if md_file.exists():
+                    return md_file
+
+            return target if target.exists() else None
+
+    def find_md_root(self, current_path: Path) -> Optional[Path]:
+        """Find the md root directory by walking up the path."""
+        path = current_path
+        while path != path.parent:
+            if path.name == 'md':
+                return path
+            path = path.parent
+        return None
+
+    def get_file_info(self, file_path: Path) -> Dict:
+        """Get information about a markdown file."""
+        info = {
+            'path': str(file_path.relative_to(self.base_path)),
+            'exists': file_path.exists(),
+            'size': 0,
+            'title': None
+        }
+
+        if file_path.exists():
+            try:
+                info['size'] = file_path.stat().st_size
+
+                # Extract title from file (first H1)
+                with open(file_path, 'r', encoding='utf-8') as f:
+                    content = f.read()
+                    h1_match = re.search(r'^# (.+)$', content, re.MULTILINE)
+                    if h1_match:
+                        info['title'] = h1_match.group(1).strip()
+            except Exception as e:
+                print(f"âš ï¸  Error getting file info for {file_path}: {e}")
+
+        return info
+
+    def build_tree(self, md_file: Path, current_depth: int = 0, max_depth: int = 10) -> Dict:
+        """Recursively build the markdown tree starting from an index.md file."""
+        if current_depth > max_depth:
+            return {'error': 'Max depth exceeded'}
+
+        # Avoid infinite loops
+        file_key = str(md_file.resolve())
+        if file_key in self.visited_files:
+            return {'error': 'Circular reference detected', 'path': file_key}
+
+        self.visited_files.add(file_key)
+
+        print("  " * current_depth + f"ðŸ“„ Processing: {md_file.relative_to(self.base_path)}")
+
+        # Get file information
+        file_info = self.get_file_info(md_file)
+
+        # Get subpages
+        subpages_links = self.extract_subpages_links(md_file)
+
+        node = {
+            'file_info': file_info,
+            'subpages_count': len(subpages_links),
+            'subpages': []
+        }
+
+        # Process each subpage
+        for link_info in subpages_links:
+            print("  " * (current_depth + 1) + f"ðŸ”— Link: {link_info['title']} -> {link_info['link']}")
+
+            # Resolve the link path
+            target_path = self.resolve_link_path(md_file.parent, link_info['link'])
+
+            subpage_node = {
+                'title': link_info['title'],
+                'link': link_info['link'],
+                'resolved_path': str(target_path.relative_to(self.base_path)) if target_path else None,
+                'exists': target_path.exists() if target_path else False
+            }
+
+            # If target exists and is an index.md, recurse
+            if target_path and target_path.exists() and target_path.name == 'index.md':
+                subpage_node['children'] = self.build_tree(target_path, current_depth + 1, max_depth)
+            elif target_path and target_path.exists():
+                # It's a regular markdown file
+                subpage_node['file_info'] = self.get_file_info(target_path)
+
+            node['subpages'].append(subpage_node)
+
+        return node
+
+    def build_variant_tree(self, variant: str) -> Dict:
+        """Build the complete tree for a specific variant."""
+        print(f"\nðŸŒ³ Building tree for variant: {variant}")
+
+        # Reset visited files for each variant
+        self.visited_files.clear()
+
+        # Find the root index.md for this variant
+        root_index = self.base_path / "dist" / "docs" / "v2" / variant / "md" / "index.md"
+
+        if not root_index.exists():
+            return {'error': f'Root index.md not found for variant {variant}'}
+
+        return {
+            'variant': variant,
+            'root_path': str(root_index.relative_to(self.base_path)),
+            'tree': self.build_tree(root_index)
+        }
+
+    def generate_report(self, trees: Dict[str, Dict]) -> Dict:
+        """Generate a summary report of the trees."""
+        report = {
+            'total_variants': len(trees),
+            'variants': {},
+            'summary': {
+                'total_files': 0,
+                'total_subpages': 0,
+                'broken_links': 0
+            }
+        }
+
+        def count_nodes(node):
+            """Recursively count files and links in a tree node."""
+            counts = {'files': 0, 'subpages': 0, 'broken_links': 0}
+
+            if 'file_info' in node:
+                counts['files'] += 1
+
+            if 'subpages' in node:
+                counts['subpages'] += len(node['subpages'])
+                for subpage in node['subpages']:
+                    if not subpage.get('exists', True):
+                        counts['broken_links'] += 1
+                    if 'children' in subpage:
+                        child_counts = count_nodes(subpage['children'])
+                        counts['files'] += child_counts['files']
+                        counts['subpages'] += child_counts['subpages']
+                        counts['broken_links'] += child_counts['broken_links']
+
+            return counts
+
+        for variant, tree in trees.items():
+            if 'tree' in tree:
+                counts = count_nodes(tree['tree'])
+                report['variants'][variant] = counts
+                report['summary']['total_files'] += counts['files']
+                report['summary']['total_subpages'] += counts['subpages']
+                report['summary']['broken_links'] += counts['broken_links']
+
+        return report
+
+    def read_markdown_file(self, file_path: Path) -> str:
+        """Read the content of a markdown file."""
+        try:
+            with open(file_path, 'r', encoding='utf-8') as f:
+                return f.read()
+        except Exception as e:
+            print(f"Error reading {file_path}: {e}")
+            return ""
+
+    def clean_markdown_content(self, content: str) -> str:
+        """Clean markdown content by removing metadata sections."""
+        # Remove the Source/URL/Date footer section
+        content = re.sub(r'\n---\n\*\*Source\*\*:.*?(?=\n\n|\Z)', '', content, flags=re.DOTALL)
+
+        # Ensure content ends with proper spacing
+        content = content.rstrip() + '\n'
+
+        return content
+
+    def build_consolidated_document(self, tree: Dict, variant: str, path_breadcrumb: List[str] = None) -> str:
+        """Build a consolidated markdown document from the tree structure."""
+        if path_breadcrumb is None:
+            path_breadcrumb = []
+
+        consolidated = []
+
+        # Process the current file if it exists
+        if 'file_info' in tree and tree['file_info']['exists']:
+            file_path = Path(tree['file_info']['path'])
+            relative_source = str(file_path.relative_to(Path(f'dist/docs/v2/{variant}/md')))
+
+            # Read the file content
+            content = self.read_markdown_file(self.base_path / file_path)
+            content = self.clean_markdown_content(content)
+
+            # Add page metadata header (except for root)
+            if path_breadcrumb:
+                breadcrumb_path = ' > '.join(path_breadcrumb)
+                page_header = f"""---
+**PAGE: {breadcrumb_path}**
+**SOURCE: {relative_source}**
+
+"""
+                consolidated.append(page_header)
+
+            # Add the content
+            consolidated.append(content)
+
+        # Process subpages with depth-first traversal (avoid duplication)
+        if 'subpages' in tree:
+            for subpage in tree['subpages']:
+                # Build new breadcrumb path
+                new_breadcrumb = path_breadcrumb + [subpage['title']]
+
+                # Process the subpage itself (if it exists as a file)
+                if subpage.get('exists', False) and subpage.get('resolved_path'):
+                    # Handle the subpage file
+                    file_path = Path(subpage['resolved_path'])
+                    content = self.read_markdown_file(self.base_path / file_path)
+                    content = self.clean_markdown_content(content)
+
+                    breadcrumb_path = ' > '.join(new_breadcrumb)
+                    relative_source = str(file_path.relative_to(Path(f'dist/docs/v2/{variant}/md')))
+
+                    page_header = f"""---
+**PAGE: {breadcrumb_path}**
+**SOURCE: {relative_source}**
+
+"""
+                    consolidated.append(page_header)
+                    consolidated.append(content)
+
+                # Then, recursively process its children (depth-first) - only if it has children
+                if 'children' in subpage:
+                    child_content = self.build_consolidated_document(
+                        subpage['children'],
+                        variant,
+                        new_breadcrumb
+                    )
+                    if child_content.strip():  # Only append if there's actual content
+                        consolidated.append(child_content)
+
+        return '\n'.join(consolidated)
+
+def main():
+    base_path = Path.cwd()
+    builder = MarkdownTreeBuilder(base_path)
+
+    # Step 1: Regenerate documentation
+    if not builder.run_make_dist():
+        print("âŒ Failed to regenerate documentation. Exiting.")
+        sys.exit(1)
+
+    # Step 2: Find variants
+    variants = builder.find_variants()
+    if not variants:
+        print("âŒ No variants found. Exiting.")
+        sys.exit(1)
+
+    # Step 3: Build trees for each variant
+    trees = {}
+    for variant in variants:
+        trees[variant] = builder.build_variant_tree(variant)
+
+    # Step 4: Generate report
+    report = builder.generate_report(trees)
+
+    # Step 5: Save results
+    output_file = base_path / "markdown_tree_analysis.json"
+
+    result = {
+        'timestamp': '2025-12-05',
+        'base_path': str(base_path),
+        'report': report,
+        'trees': trees
+    }
+
+    with open(output_file, 'w', encoding='utf-8') as f:
+        json.dump(result, f, indent=2, ensure_ascii=False)
+
+    print(f"\nðŸ“Š Analysis complete! Results saved to: {output_file}")
+    print(f"ðŸ“ˆ Summary:")
+    print(f"  - Total variants: {report['total_variants']}")
+    print(f"  - Total files processed: {report['summary']['total_files']}")
+    print(f"  - Total subpage links: {report['summary']['total_subpages']}")
+    print(f"  - Broken links found: {report['summary']['broken_links']}")
+
+    for variant, counts in report['variants'].items():
+        print(f"  - {variant}: {counts['files']} files, {counts['subpages']} links, {counts['broken_links']} broken")
+
+    # Step 6: Generate consolidated documents for each variant
+    for variant in variants:
+        if variant in trees and 'tree' in trees[variant]:
+            print(f"\nðŸ“– Generating consolidated document for variant: {variant}")
+            consolidated_content = builder.build_consolidated_document(trees[variant]['tree'], variant)
+
+            # Add header
+            header = f"""# Documentation
+**Variant:** {variant}
+**Generated:** 2025-12-05
+
+This is a consolidated view of all documentation pages in hierarchical order.
+
+"""
+            full_content = header + consolidated_content
+
+            # Save consolidated document
+            consolidated_file = base_path / f"consolidated_{variant}_docs.md"
+            with open(consolidated_file, 'w', encoding='utf-8') as f:
+                f.write(full_content)
+
+            print(f"  ðŸ“Š Generated document with {len(consolidated_content.split('---'))-1} pages, {len(full_content):,} characters")
+            print(f"ðŸ“„ Saved consolidated document: {consolidated_file}")
+
+    return 0
+
+if __name__ == '__main__':
+    sys.exit(main())
\ No newline at end of file
diff --git a/themes/union/layouts/_default/list.md b/themes/union/layouts/_default/list.md
new file mode 100644
index 00000000..2a26caac
--- /dev/null
+++ b/themes/union/layouts/_default/list.md
@@ -0,0 +1,43 @@
+{{ define "main" }}
+{{- /*
+Template for generating markdown versions of section/list pages.
+This renders section content and lists child pages in markdown format.
+*/ -}}
+{{- $title := .Title -}}
+
+# {{ $title }}
+
+{{- if .Params.description }}
+
+{{ .Params.description }}
+{{- end }}
+
+{{ .RawContent }}
+
+{{- if .Pages }}
+
+## Pages in this section
+
+{{- range .Pages.ByWeight }}
+{{- if (partial "page-allowed.html" .).allowed }}
+{{- $section := "" }}
+{{- if eq .Kind "section" }}
+{{- /* For section pages (directories), get the directory name from File.Dir */}}
+{{- $section = strings.TrimSuffix "/" .File.Dir }}
+{{- $section = path.Base $section }}
+{{- else }}
+{{- /* For regular pages (files), use the file's base name */}}
+{{- $section = .File.BaseFileName }}
+{{- end }}
+- [{{ .Title }}]({{ $section }}/) {{- if .Params.description }} - {{ .Params.description }}{{ end }}
+{{- end }}
+{{- end }}
+{{- end }}
+
+---
+**Source**: {{ .File.Path }}
+**URL**: {{ .Permalink }}
+{{- if .Date }}
+**Date**: {{ .Date.Format "2006-01-02" }}
+{{- end }}
+{{ end }}
\ No newline at end of file
diff --git a/themes/union/layouts/_default/single.md b/themes/union/layouts/_default/single.md
new file mode 100644
index 00000000..b315a74c
--- /dev/null
+++ b/themes/union/layouts/_default/single.md
@@ -0,0 +1,26 @@
+{{ define "main" }}
+{{- /*
+Template for generating markdown versions of individual pages.
+This renders the content with shortcodes processed for markdown output.
+*/ -}}
+{{- $title := .Title -}}
+
+# {{ $title }}
+
+{{- if .Params.description }}
+
+{{ .Params.description }}
+{{- end }}
+
+{{ .RawContent }}
+
+---
+**Source**: {{ .File.Path }}
+**URL**: {{ .Permalink }}
+{{- if .Date }}
+**Date**: {{ .Date.Format "2006-01-02" }}
+{{- end }}
+{{- if .Params.weight }}
+**Weight**: {{ .Params.weight }}
+{{- end }}
+{{ end }}
\ No newline at end of file
diff --git a/themes/union/theme.toml b/themes/union/theme.toml
deleted file mode 100644
index 6c341b56..00000000
--- a/themes/union/theme.toml
+++ /dev/null
@@ -1,10 +0,0 @@
-name = "Union.AI"
-description = "Union site style with language variant support"
-homepage = "https://docs.union.ai/"
-tags = ["docs", "documentation", "responsive"]
-features = ["language variants", "sidebar navigation"]
-min_version = "0.41.0"
-
-[author]
-  name = "Nelson Araujo"
-  homepage = "https://github.com/unionai/unionai-docs/tree/main/themes/union"
diff --git a/unionai_docs_tools.egg-info/PKG-INFO b/unionai_docs_tools.egg-info/PKG-INFO
new file mode 100644
index 00000000..9473d1ea
--- /dev/null
+++ b/unionai_docs_tools.egg-info/PKG-INFO
@@ -0,0 +1,8 @@
+Metadata-Version: 2.4
+Name: unionai-docs-tools
+Version: 0.1.0
+Summary: Documentation build tools for Union.ai
+Requires-Python: >=3.8
+License-File: LICENSE
+Requires-Dist: toml>=0.10.2
+Dynamic: license-file
diff --git a/unionai_docs_tools.egg-info/SOURCES.txt b/unionai_docs_tools.egg-info/SOURCES.txt
new file mode 100644
index 00000000..f9e0b7c6
--- /dev/null
+++ b/unionai_docs_tools.egg-info/SOURCES.txt
@@ -0,0 +1,8 @@
+LICENSE
+README.md
+pyproject.toml
+unionai_docs_tools.egg-info/PKG-INFO
+unionai_docs_tools.egg-info/SOURCES.txt
+unionai_docs_tools.egg-info/dependency_links.txt
+unionai_docs_tools.egg-info/requires.txt
+unionai_docs_tools.egg-info/top_level.txt
\ No newline at end of file
diff --git a/unionai_docs_tools.egg-info/dependency_links.txt b/unionai_docs_tools.egg-info/dependency_links.txt
new file mode 100644
index 00000000..8b137891
--- /dev/null
+++ b/unionai_docs_tools.egg-info/dependency_links.txt
@@ -0,0 +1 @@
+
diff --git a/unionai_docs_tools.egg-info/requires.txt b/unionai_docs_tools.egg-info/requires.txt
new file mode 100644
index 00000000..24b7e928
--- /dev/null
+++ b/unionai_docs_tools.egg-info/requires.txt
@@ -0,0 +1 @@
+toml>=0.10.2
diff --git a/unionai_docs_tools.egg-info/top_level.txt b/unionai_docs_tools.egg-info/top_level.txt
new file mode 100644
index 00000000..8b137891
--- /dev/null
+++ b/unionai_docs_tools.egg-info/top_level.txt
@@ -0,0 +1 @@
+
diff --git a/validate_urls.py b/validate_urls.py
new file mode 100644
index 00000000..ac37968b
--- /dev/null
+++ b/validate_urls.py
@@ -0,0 +1,194 @@
+#!/usr/bin/env python3
+"""
+URL Validator for Processed Markdown Files
+
+This script scans all processed markdown files to ensure URLs are properly normalized
+to be absolute paths or valid external URLs.
+"""
+
+import re
+import sys
+from pathlib import Path
+from typing import List, Tuple, Set
+import argparse
+
+
+class URLValidator:
+    def __init__(self, base_dir: str):
+        self.base_dir = Path(base_dir)
+        self.issues = []
+
+    def extract_urls_from_markdown(self, content: str, file_path: str) -> List[Tuple[str, int, str]]:
+        """Extract all URLs from markdown content."""
+        urls = []
+        lines = content.split('\n')
+
+        # Pattern to match markdown links [text](url)
+        link_pattern = r'\[([^\]]*)\]\(([^)]+)\)'
+
+        for line_num, line in enumerate(lines, 1):
+            matches = re.finditer(link_pattern, line)
+            for match in matches:
+                text, url = match.groups()
+                urls.append((url, line_num, text))
+
+        return urls
+
+    def validate_url(self, url: str) -> dict:
+        """Validate a single URL and return validation results."""
+        result = {
+            'url': url,
+            'is_valid': True,
+            'issues': []
+        }
+
+        # Check for valid absolute URLs
+        if url.startswith(('http://', 'https://')):
+            result['type'] = 'external'
+            return result
+
+        # Check for absolute paths (relative to site root)
+        if url.startswith('/'):
+            result['type'] = 'absolute'
+            return result
+
+        # Check for anchor links
+        if url.startswith('#'):
+            result['type'] = 'anchor'
+            return result
+
+        # Special URLs that are OK to be relative
+        if url.startswith(('mailto:', 'tel:', 'javascript:')):
+            result['type'] = 'special'
+            return result
+
+        # Skip API reference links (these are generated by Hugo from TypeDoc)
+        if '../packages/' in url or url in ['Protocol']:
+            result['type'] = 'api-reference'
+            return result
+
+        # Accept relative paths that are within md-processed directory structure
+        if url.startswith('../') or url.startswith('./') or (not url.startswith('/') and not '://' in url):
+            result['type'] = 'relative'
+            # Only flag as invalid if it seems to go way outside the structure
+            if url.count('../') > 10:  # Very generous limit
+                result['is_valid'] = False
+                result['issues'].append(f"URL may go outside md-processed directory: '{url}'")
+            return result
+
+        # Should not reach here, but handle unexpected cases
+        result['is_valid'] = False
+        result['issues'].append(f"Unexpected URL format: '{url}'")
+        result['type'] = 'unknown'
+
+        return result
+
+    def scan_file(self, file_path: Path) -> None:
+        """Scan a single markdown file for URL issues."""
+        try:
+            with open(file_path, 'r', encoding='utf-8') as f:
+                content = f.read()
+
+            urls = self.extract_urls_from_markdown(content, str(file_path))
+
+            for url, line_num, link_text in urls:
+                validation = self.validate_url(url)
+
+                if not validation['is_valid']:
+                    self.issues.append({
+                        'file': str(file_path.relative_to(self.base_dir)),
+                        'line': line_num,
+                        'url': url,
+                        'text': link_text,
+                        'issues': validation['issues']
+                    })
+
+        except Exception as e:
+            print(f"Error reading {file_path}: {e}", file=sys.stderr)
+
+    def scan_directory(self) -> None:
+        """Scan all markdown files in the directory tree."""
+        md_files = list(self.base_dir.rglob('*.txt'))  # Hugo outputs .txt for MD format
+        print(f"Scanning {len(md_files)} markdown files...")
+
+        for file_path in md_files:
+            self.scan_file(file_path)
+
+    def report(self) -> bool:
+        """Generate and print the validation report."""
+        if not self.issues:
+            print("âœ… All URLs are properly normalized!")
+            return True
+
+        print(f"âŒ Found {len(self.issues)} URL issues:")
+        print()
+
+        for issue in self.issues:
+            print(f"File: {issue['file']}:{issue['line']}")
+            print(f"  Link: [{issue['text']}]({issue['url']})")
+            for problem in issue['issues']:
+                print(f"  Issue: {problem}")
+            print()
+
+        return False
+
+    def get_url_statistics(self) -> dict:
+        """Get statistics about URL types found."""
+        stats = {
+            'external': 0,
+            'absolute': 0,
+            'anchor': 0,
+            'relative': 0,
+            'special': 0,
+            'api-reference': 0,
+            'total': 0
+        }
+
+        md_files = list(self.base_dir.rglob('*.txt'))
+        all_urls = []
+
+        for file_path in md_files:
+            try:
+                with open(file_path, 'r', encoding='utf-8') as f:
+                    content = f.read()
+                urls = self.extract_urls_from_markdown(content, str(file_path))
+                all_urls.extend(urls)
+            except:
+                continue
+
+        for url, _, _ in all_urls:
+            validation = self.validate_url(url)
+            stats[validation['type']] += 1
+            stats['total'] += 1
+
+        return stats
+
+
+def main():
+    parser = argparse.ArgumentParser(description='Validate URLs in processed markdown files')
+    parser.add_argument('directory', help='Directory containing processed markdown files')
+    parser.add_argument('--stats', action='store_true', help='Show URL statistics')
+    args = parser.parse_args()
+
+    validator = URLValidator(args.directory)
+
+    if args.stats:
+        stats = validator.get_url_statistics()
+        print("URL Statistics:")
+        print(f"  Total URLs: {stats['total']}")
+        print(f"  External (http/https): {stats['external']}")
+        print(f"  Absolute paths (/...): {stats['absolute']}")
+        print(f"  Anchor links (#...): {stats['anchor']}")
+        print(f"  API Reference links: {stats['api-reference']}")
+        print(f"  Relative paths (need fixing): {stats['relative']}")
+        print(f"  Special (mailto/tel/etc): {stats['special']}")
+        print()
+
+    validator.scan_directory()
+    success = validator.report()
+
+    return 0 if success else 1
+
+
+if __name__ == '__main__':
+    sys.exit(main())
\ No newline at end of file
