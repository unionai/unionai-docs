---
title: Serve LLMs with Ollama
weight: 1
variants: +flyte -serverless -byoc -selfmanaged
layout: py_example
example_file: /external/unionai-examples/v1/flyte-integrations/flytekit-plugins/ollama_plugin/ollama_plugin/serve_llm.py
---